{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"FIRST_NAME = \"Asemaneh\" # replace with your first name\nLAST_NAME = \"Nafe\" # replace with your last name\nSTUDENT_ID = 400105285 # replace with your student id\nWANDB_ID = \"asemanehnafe\" # replace with your wandb username\nPROJECT_NAME = f\"{FIRST_NAME}-{LAST_NAME}-DQN-EXPLORE-HW\"\nprint(f\"Project name: {PROJECT_NAME}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:35:28.917471Z","iopub.execute_input":"2025-06-11T08:35:28.917751Z","iopub.status.idle":"2025-06-11T08:35:28.922421Z","shell.execute_reply.started":"2025-06-11T08:35:28.917730Z","shell.execute_reply":"2025-06-11T08:35:28.921713Z"}},"outputs":[{"name":"stdout","text":"Project name: Asemaneh-Nafe-DQN-EXPLORE-HW\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(f\"Check my results at https://wandb.ai/{WANDB_ID}/{PROJECT_NAME}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:35:30.555786Z","iopub.execute_input":"2025-06-11T08:35:30.556454Z","iopub.status.idle":"2025-06-11T08:35:30.560488Z","shell.execute_reply.started":"2025-06-11T08:35:30.556430Z","shell.execute_reply":"2025-06-11T08:35:30.559745Z"}},"outputs":[{"name":"stdout","text":"Check my results at https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Set DEBUG to True if you are still implementing the code and debugging\n# and don't want to make your wandb dashboard messy.\n# set DEBUG to False if you are almost done with the implementation\n# and want check performance and compare hyperparameters and models\nDEBUG = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:35:32.683723Z","iopub.execute_input":"2025-06-11T08:35:32.684006Z","iopub.status.idle":"2025-06-11T08:35:32.687400Z","shell.execute_reply.started":"2025-06-11T08:35:32.683985Z","shell.execute_reply":"2025-06-11T08:35:32.686652Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!apt install build-essential python3-dev\n!git clone https://github.com/DeepRLCourse/Homework-10.git\n%pip install swig\n%pip install \"Homework-10/BootstrapDQN\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:35:33.807654Z","iopub.execute_input":"2025-06-11T08:35:33.807910Z","iopub.status.idle":"2025-06-11T08:38:02.486479Z","shell.execute_reply.started":"2025-06-11T08:35:33.807891Z","shell.execute_reply":"2025-06-11T08:38:02.485689Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nbuild-essential is already the newest version (12.9ubuntu3).\npython3-dev is already the newest version (3.10.6-1~22.04.1).\npython3-dev set to manually installed.\n0 upgraded, 0 newly installed, 0 to remove and 87 not upgraded.\nCloning into 'Homework-10'...\nremote: Enumerating objects: 111, done.\u001b[K\nremote: Counting objects: 100% (111/111), done.\u001b[K\nremote: Compressing objects: 100% (67/67), done.\u001b[K\nremote: Total 111 (delta 37), reused 108 (delta 34), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (111/111), 1.14 MiB | 16.66 MiB/s, done.\nResolving deltas: 100% (37/37), done.\nCollecting swig\n  Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\nDownloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: swig\nSuccessfully installed swig-4.3.1\nNote: you may need to restart the kernel to use updated packages.\nProcessing ./Homework-10/BootstrapDQN\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: ale-py<=0.11.0,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (0.10.2)\nCollecting dotenv>=0.9.9 (from main==0.1.0)\n  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\nCollecting gymnasium>=1.1.1 (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0)\n  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting ipykernel>=6.29.5 (from main==0.1.0)\n  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: nbformat>=5.10.4 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (5.10.4)\nRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (1.26.4)\nCollecting pip>=25.0.1 (from main==0.1.0)\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: swig>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (4.3.1)\nRequirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (2.6.0+cu124)\nRequirement already satisfied: wandb>=0.19.9 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (0.19.9)\nCollecting python-dotenv (from dotenv>=0.9.9->main==0.1.0)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (3.1.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (4.13.2)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (0.0.4)\nCollecting box2d-py==2.3.5 (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0)\n  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (2.6.1)\nRequirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (0.2.2)\nRequirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (1.8.0)\nRequirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (7.34.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (8.6.3)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (5.7.2)\nRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (0.1.7)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (1.6.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (7.0.0)\nRequirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (24.0.1)\nRequirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (6.4.2)\nRequirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (5.7.1)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.10.4->main==0.1.0) (2.21.1)\nRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.10.4->main==0.1.0) (4.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->main==0.1.0) (1.3.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (3.20.3)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.11.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (75.2.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.19.9->main==0.1.0) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.19.9->main==0.1.0) (4.0.12)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (3.0.50)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (0.24.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.29.5->main==0.1.0) (2.9.0.post0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->main==0.1.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->main==0.1.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->main==0.1.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.19.9->main==0.1.0) (5.0.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.2.13)\nDownloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\nDownloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nBuilding wheels for collected packages: main, box2d-py\n  Building wheel for main (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for main: filename=main-0.1.0-py3-none-any.whl size=11117 sha256=650e959efb47b8da0d3bdec54f965990d599881becebf59448ffc51c51e9a996\n  Stored in directory: /tmp/pip-ephem-wheel-cache-cg0spch6/wheels/4f/16/b7/f0afc1a4a4574831edbabf07feb162c98e9e62978951f878e1\n  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379365 sha256=148d4919793f16b5f53ce363f90add153a5420c64bf8180d8707b704c81f37a8\n  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\nSuccessfully built main box2d-py\nInstalling collected packages: box2d-py, python-dotenv, pip, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dotenv, nvidia-cusolver-cu12, ipykernel, gymnasium, main\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n  Attempting uninstall: ipykernel\n    Found existing installation: ipykernel 6.17.1\n    Uninstalling ipykernel-6.17.1:\n      Successfully uninstalled ipykernel-6.17.1\n  Attempting uninstall: gymnasium\n    Found existing installation: gymnasium 0.29.0\n    Uninstalling gymnasium-0.29.0:\n      Successfully uninstalled gymnasium-0.29.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.11 requires gymnasium==0.29.0, but you have gymnasium 1.1.1 which is incompatible.\nstable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.1.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires ipykernel==6.17.1, but you have ipykernel 6.29.5 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed box2d-py-2.3.5 dotenv-0.9.9 gymnasium-1.1.1 ipykernel-6.29.5 main-0.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pip-25.1.1 python-dotenv-1.1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\nfrom bootstrapdqn import ReplayBuffer, BaseDQNAgent, get_machine, set_wandb_key_form_secrets, envs\nimport torch\nfrom torch import nn\nimport wandb\nimport random\nimport gymnasium as gym\nimport ale_py\nimport time\n\ngym.register_envs(ale_py)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:40:20.147844Z","iopub.execute_input":"2025-06-11T08:40:20.148525Z","iopub.status.idle":"2025-06-11T08:40:25.666528Z","shell.execute_reply.started":"2025-06-11T08:40:20.148485Z","shell.execute_reply":"2025-06-11T08:40:25.665800Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\nTA = True if WANDB_ID == \"alireza9\" else False\nSAVE_CODE = False if TA else True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:40:26.748390Z","iopub.execute_input":"2025-06-11T08:40:26.748757Z","iopub.status.idle":"2025-06-11T08:40:26.752739Z","shell.execute_reply.started":"2025-06-11T08:40:26.748737Z","shell.execute_reply":"2025-06-11T08:40:26.752056Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(SAVE_CODE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:40:29.707385Z","iopub.execute_input":"2025-06-11T08:40:29.707666Z","iopub.status.idle":"2025-06-11T08:40:29.711879Z","shell.execute_reply.started":"2025-06-11T08:40:29.707644Z","shell.execute_reply":"2025-06-11T08:40:29.711140Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\n# IF YOU CHANGE ANYTHING ABOUT ENVIRONMENTS AND THEIR RUN CONFIGS, YOUR CODE WILL NOT BE GRADED\nfrom pprint import pprint\nENVS = envs()\npprint(ENVS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:40:36.268725Z","iopub.execute_input":"2025-06-11T08:40:36.269487Z","iopub.status.idle":"2025-06-11T08:40:36.274501Z","shell.execute_reply.started":"2025-06-11T08:40:36.269461Z","shell.execute_reply":"2025-06-11T08:40:36.273844Z"}},"outputs":[{"name":"stdout","text":"{'CartPole': {'env': {'env_config': {}, 'env_name': 'CartPole-v1', 'seed': 43},\n              'run': {'max_episodes': 1000,\n                      'max_steps': 50000,\n                      'max_steps_per_episode': 100000,\n                      'max_time': 720.0}},\n 'FrozenLake': {'env': {'env_config': {'p': 0.87, 'size': 14},\n                        'env_name': 'FrozenLake-v1',\n                        'seed': 42},\n                'run': {'max_episodes': 1000000,\n                        'max_steps': 1000000,\n                        'max_steps_per_episode': 100000,\n                        'max_time': 14400}},\n 'LunarLander': {'env': {'env_config': {},\n                         'env_name': 'LunarLander-v3',\n                         'seed': 43},\n                 'run': {'max_episodes': 100000,\n                         'max_steps': 200000,\n                         'max_steps_per_episode': 100000,\n                         'max_time': 7200}},\n 'MountainCar': {'env': {'env_config': {},\n                         'env_name': 'MountainCar-v0',\n                         'seed': 43},\n                 'run': {'max_episodes': 100000,\n                         'max_steps': 300000,\n                         'max_steps_per_episode': 100000,\n                         'max_time': 9000.0}},\n 'SeaQuest': {'env': {'env_config': {},\n                      'env_name': 'Seaquest-ramNoFrameskip-v4',\n                      'seed': 43},\n              'run': {'max_episodes': 1000000,\n                      'max_steps': 2000000,\n                      'max_steps_per_episode': 1000000,\n                      'max_time': 28800}}}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"if not DEBUG:\n    set_wandb_key_form_secrets()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:40:39.238198Z","iopub.execute_input":"2025-06-11T08:40:39.238470Z","iopub.status.idle":"2025-06-11T08:40:39.367613Z","shell.execute_reply.started":"2025-06-11T08:40:39.238451Z","shell.execute_reply":"2025-06-11T08:40:39.366910Z"}},"outputs":[{"name":"stdout","text":"your machine is detected as Kaggle\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"class EpsGreedyDQNAgent(BaseDQNAgent):\n    \"\"\"\n    Epsilon-greedy DQN agent.\n    \"\"\"\n\n    def __init__(self, epsilon: float = 0.1, eps_decay: float = 0.999, eps_min: float = 0.01, **kwargs):\n        super().__init__(**kwargs)\n        self.epsilon = epsilon\n        self.eps_decay = eps_decay\n        self.eps_min = eps_min\n\n    def _decay_eps(self):\n        \"\"\"\n        Decay the epsilon value.\n        \"\"\"\n        self.epsilon = max(self.epsilon * self.eps_decay, self.eps_min)\n\n    def _create_replay_buffer(self, max_size=1000000):\n        self.replay_buffer = ReplayBuffer(\n            [\n                (\"state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"action\", (), torch.int64),\n                (\"reward\", (), torch.float32),\n                (\"next_state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"done\", (), torch.float32),\n            ],\n            max_size=max_size,\n            device=self.device,\n        )\n\n    def _create_network(self):\n        self.q_network = nn.Sequential(\n            nn.Linear(self.env.observation_space.shape[0], 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, self.env.action_space.n),\n        ).to(self.device)\n        self.q_network.apply(\n            lambda m: torch.nn.init.orthogonal_(m.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n            if isinstance(m, nn.Linear)\n            else None\n        )\n        self.target_network = nn.Sequential(\n            nn.Linear(self.env.observation_space.shape[0], 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, self.env.action_space.n),\n        ).to(self.device)\n\n    def _compute_loss(self, batch):\n        \"\"\"\n        Compute the loss for the DQN agent.\n        \"\"\"\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n\n        q_values = self.q_network(states).gather(1, actions.unsqueeze(1)).squeeze()\n        next_q_values = self.target_network(next_states).max(1)[0]\n        expected_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n\n        loss = nn.SmoothL1Loss()(q_values, expected_q_values)\n        return loss\n\n    def _act_in_training(self, state):\n        \"\"\"\n        Select an action during training.\n        \"\"\"\n        self._decay_eps()\n        if torch.rand(1).item() < self.epsilon:\n            return self.env.action_space.sample()\n        else:\n            with torch.no_grad():\n                q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n                return q_values.argmax().item()\n\n    def _act_in_eval(self, state):\n        \"\"\"\n        Select an action during evaluation.\n        \"\"\"\n        with torch.no_grad():\n            q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n            return q_values.argmax().item()\n\n    def _wandb_train_step_dict(self):\n        log_dict = super()._wandb_train_step_dict()\n        log_dict[\"train_step/epsilon\"] = self.epsilon\n        return log_dict\n\n    def _save_dict(self):\n        save_dict = super()._save_dict()\n        save_dict[\"epsilon\"] = self.epsilon\n        save_dict[\"eps_decay\"] = self.eps_decay\n        save_dict[\"eps_min\"] = self.eps_min\n        return save_dict\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:40:41.717034Z","iopub.execute_input":"2025-06-11T08:40:41.717297Z","iopub.status.idle":"2025-06-11T08:40:41.729007Z","shell.execute_reply.started":"2025-06-11T08:40:41.717276Z","shell.execute_reply":"2025-06-11T08:40:41.728416Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class MultiHeadQNet(nn.Module):\n    def __init__(self, input_dim, output_dim, k):\n        super().__init__()\n        self.k = k\n        self.shared = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU()\n        )\n        self.heads = nn.ModuleList([\n            nn.Linear(256, output_dim) for _ in range(k)\n        ])\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            torch.nn.init.orthogonal_(m.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n\n    def forward(self, x):\n        shared_out = self.shared(x)\n        return torch.stack([head(shared_out) for head in self.heads], dim=1)  # [B, K, A]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:40:44.852119Z","iopub.execute_input":"2025-06-11T08:40:44.852386Z","iopub.status.idle":"2025-06-11T08:40:44.858560Z","shell.execute_reply.started":"2025-06-11T08:40:44.852357Z","shell.execute_reply":"2025-06-11T08:40:44.857642Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class BootstrapDQNAgent(EpsGreedyDQNAgent):\n    def __init__(self, k: int = 10, bernoulli_p: float = 0.5, **kwargs):\n        self.k = k\n        self.bernoulli_p = bernoulli_p\n        self.current_head = 0\n        super().__init__(**kwargs)\n\n    def _create_network(self):\n        obs_dim = self.env.observation_space.shape[0]\n        action_dim = self.env.action_space.n\n\n        self.q_network = MultiHeadQNet(obs_dim, action_dim, self.k).to(self.device)\n        self.target_network = MultiHeadQNet(obs_dim, action_dim, self.k).to(self.device)\n\n    def _create_replay_buffer(self, max_size=1000000):\n        self.replay_buffer = ReplayBuffer(\n            [\n                (\"state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"action\", (), torch.int64),\n                (\"reward\", (), torch.float32),\n                (\"next_state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"done\", (), torch.float32),\n                (\"mask\", (self.k,), torch.bool),  # additional field for head masking\n            ],\n            max_size=max_size,\n            device=self.device,\n        )\n\n    def _preprocess_add(self, state, action, reward, next_state, done):\n        state = torch.as_tensor(state, dtype=torch.float32, device=self.device)\n        action = torch.as_tensor(action, dtype=torch.int64, device=self.device)\n        reward = torch.as_tensor(reward, dtype=torch.float32, device=self.device)\n        next_state = torch.as_tensor(next_state, dtype=torch.float32, device=self.device)\n        done = torch.as_tensor(done, dtype=torch.float32, device=self.device)\n    \n        mask = torch.bernoulli(torch.full((self.k,), self.bernoulli_p, dtype=torch.float32, device=self.device)).bool()\n    \n        return {\n            \"state\": state,\n            \"action\": action,\n            \"reward\": reward,\n            \"next_state\": next_state,\n            \"done\": done,\n            \"mask\": mask,\n        }\n\n\n    def _compute_loss(self, batch):\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        masks = batch[\"mask\"]  # [B, K]\n\n        all_q = self.q_network(states)          # [B, K, A]\n        all_q_target = self.target_network(next_states)  # [B, K, A]\n\n        loss = 0\n        for head in range(self.k):\n            head_mask = masks[:, head]\n            if head_mask.sum() == 0:\n                continue  # skip if no samples for this head\n\n            q = all_q[head_mask, head, :].gather(1, actions[head_mask].unsqueeze(1)).squeeze()\n            next_q = all_q_target[head_mask, head, :].max(1)[0]\n            target = rewards[head_mask] + (1 - dones[head_mask]) * self.gamma * next_q\n            loss += nn.SmoothL1Loss()(q, target)\n\n        return loss / self.k\n\n    def _episode(self):\n        super()._episode()\n        self.current_head = random.randint(0, self.k - 1)\n\n    def _act_in_training(self, state):\n        # self._decay_eps()\n        # if torch.rand(1).item() < self.epsilon:\n        #     return self.env.action_space.sample()\n        # else:\n        with torch.no_grad():\n            state_tensor = torch.as_tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n            q_values = self.q_network(state_tensor)[0, self.current_head]\n            return q_values.argmax().item()\n\n    def _act_in_eval(self, state):\n        with torch.no_grad():\n            state_tensor = torch.as_tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n            q_values = self.q_network(state_tensor)[0].mean(dim=0)  # average over heads\n            return q_values.argmax().item()\n\n    def _wandb_train_episode_dict(self):\n        log_dict = super()._wandb_train_episode_dict()\n        log_dict[\"train_episode/current_head\"] = self.current_head\n        return log_dict\n\n    def _save_dict(self):\n        save_dict = super()._save_dict()\n        save_dict[\"k\"] = self.k\n        save_dict[\"bernoulli_p\"] = self.bernoulli_p\n        return save_dict\n    def train(\n        self,\n        max_episodes=10000,\n        max_steps_per_episode=5000,\n        max_steps=1000000,\n        max_time=4 * 60 * 60,\n        learn_every=10,\n        eval_every=10000,\n    ):\n        \"\"\"\n        Train the agent over multiple episodes, performing learning updates and periodic evaluations.\n        \"\"\"\n        start_time = time.time()\n        pre_evaluation_step = self._training_step\n        max_steps += self._training_step\n        finished = False\n\n        for episode in range(max_episodes):\n            if episode % 50 == 0:\n                print(f\"episode: {episode}\")\n            self.train_mode()\n            self.env.action_space.seed(random.randint(0, 1e32 - 1))\n            state, _ = self.env.reset(seed=random.randint(0, 1e32 - 1))\n            for step in range(max_steps_per_episode):\n                action = self.act(state)\n                next_state, reward, terminated, truncated, _ = self.env.step(action)\n                done = terminated or truncated\n\n                self._step(reward)\n                self.add_experience(state, action, reward, next_state, done)\n\n                state = next_state\n\n                if self._total_steps % learn_every == 0:\n                    self.learn()\n\n                if done:\n                    break\n\n                if self._training_step >= max_steps or time.time() - start_time >= max_time:\n                    finished = True\n                    break\n\n            self._episode()\n\n            if self._training_step - pre_evaluation_step >= eval_every:\n                self.evaluate()\n                pre_evaluation_step = self._training_step\n\n            if finished:\n                self.evaluate()\n                print(f\"Trained for {self._training_step} steps.\")\n                break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:40:46.888095Z","iopub.execute_input":"2025-06-11T08:40:46.888358Z","iopub.status.idle":"2025-06-11T08:40:47.025814Z","shell.execute_reply.started":"2025-06-11T08:40:46.888338Z","shell.execute_reply":"2025-06-11T08:40:47.025132Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class PriorMultiHeadQNet(nn.Module):\n    def __init__(self, input_dim, output_dim, k):\n        super().__init__()\n        self.k = k\n        self.shared = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n        )\n        self.heads = nn.ModuleList([\n            nn.Linear(64, output_dim) for _ in range(k)\n        ])\n        self._freeze_weights()\n\n    def _freeze_weights(self):\n        for param in self.parameters():\n            param.requires_grad = False  # Ensure prior is fixed\n\n    def forward(self, x):\n        shared_out = self.shared(x)\n        return torch.stack([head(shared_out) for head in self.heads], dim=1)  # [B, K, A]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:40:51.947886Z","iopub.execute_input":"2025-06-11T08:40:51.948552Z","iopub.status.idle":"2025-06-11T08:40:51.953630Z","shell.execute_reply.started":"2025-06-11T08:40:51.948531Z","shell.execute_reply":"2025-06-11T08:40:51.952908Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class RPFBootstrapDQNAgent(BootstrapDQNAgent):\n    def _create_network(self):\n        super()._create_network()\n\n        input_dim = self.env.observation_space.shape[0]\n        output_dim = self.env.action_space.n\n\n        self.prior_network = PriorMultiHeadQNet(input_dim, output_dim, self.k).to(self.device)\n\n    def _act_in_training(self, state):\n        # self._decay_eps()\n        # if torch.rand(1).item() < self.epsilon:\n        #     return self.env.action_space.sample()\n        # else:\n        with torch.no_grad():\n            state_tensor = torch.as_tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n            q = self.q_network(state_tensor)[0, self.current_head] + \\\n                self.prior_network(state_tensor)[0, self.current_head]\n            return q.argmax().item()\n\n    def _act_in_eval(self, state):\n        with torch.no_grad():\n            state_tensor = torch.as_tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n            q = self.q_network(state_tensor)\n            return q.mean(dim=1).squeeze().argmax().item()\n\n    def _compute_loss(self, batch):\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        masks = batch[\"mask\"]\n\n        all_q = self.q_network(states) + self.prior_network(states)              # [B, K, A]\n        all_q_target = self.target_network(next_states) + self.prior_network(next_states)\n\n        loss = 0\n        for head in range(self.k):\n            head_mask = masks[:, head]\n            if head_mask.sum() == 0:\n                continue\n\n            q = all_q[head_mask, head, :].gather(1, actions[head_mask].unsqueeze(1)).squeeze()\n            next_q = all_q_target[head_mask, head, :].max(1)[0]\n            target = rewards[head_mask] + (1 - dones[head_mask]) * self.gamma * next_q\n            loss += nn.SmoothL1Loss()(q, target)\n\n        return loss / self.k\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:41:34.190035Z","iopub.execute_input":"2025-06-11T08:41:34.190342Z","iopub.status.idle":"2025-06-11T08:41:34.198596Z","shell.execute_reply.started":"2025-06-11T08:41:34.190311Z","shell.execute_reply":"2025-06-11T08:41:34.197738Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class UEBootstrapDQNAgent(RPFBootstrapDQNAgent):\n    def __init__(self, min_ebs: float = 32, xi = None, **kwargs):\n        super().__init__(**kwargs)\n        self.min_ebs = min_ebs  # Target effective batch size\n        self.xi = xi\n\n    def _compute_loss(self, batch):\n        states = batch[\"state\"]            # [B, S]\n        actions = batch[\"action\"].unsqueeze(1)  # [B,1]\n        rewards = batch[\"reward\"].unsqueeze(1)  # [B,1]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"].unsqueeze(1)      # [B,1]\n        masks = batch[\"mask\"]             # [B, K]\n\n        B = states.size(0)\n\n        all_q = self.q_network(states) + self.prior_network(states)          # [B, K, A]\n        all_q_tgt = self.target_network(next_states) + self.prior_network(next_states)  # [B, K, A]\n\n        total_loss = 0.0\n        log_ebs = []\n\n        for j in range(self.k):\n            mask_j = masks[:, j]           # [B]\n            if mask_j.sum() == 0:\n                continue\n\n            idx = mask_j.nonzero(as_tuple=True)[0]\n            s_j = states[idx]\n            a_j = actions[idx]\n            r_j = rewards[idx]\n            ns_j = next_states[idx]\n            d_j = dones[idx]\n\n            q_j = (all_q[idx, j]          # [n_j, A]\n                   .gather(1, a_j))        # [n_j,1]\n\n            with torch.no_grad():\n                tgt_j = all_q_tgt[idx, j]\n                a_prime = tgt_j.argmax(dim=1, keepdim=True)  # [n_j,1]\n                T_j = r_j + self.gamma * tgt_j.gather(1, a_prime) * (1 - d_j)  # [n_j,1]\n\n                # Compute uncertainty across heads\n                x_l = []\n                for l in range(self.k):\n                    tmp = all_q_tgt[idx, l].gather(1, a_prime)\n                    x_l.append(tmp)\n                X = torch.stack([tmp.squeeze(1) for tmp in x_l], dim=1)  # [n_j, k]\n                sigma2 = X.var(dim=1, unbiased=False, keepdim=True)      # [n_j, 1]\n\n            weights = 1.0 / (self.gamma ** 2 * sigma2 + self.xi)  # [n_j,1]\n\n            loss_j = (weights * (q_j - T_j) ** 2).sum() / weights.sum()\n            total_loss += loss_j\n            log_ebs.append(((weights.sum() ** 2) / (weights ** 2).sum()).item())\n\n        loss = total_loss / self.k\n        self._last_ebs = torch.tensor(log_ebs).mean().item()\n        return loss\n\n    def _wandb_train_step_dict(self):\n        log = super()._wandb_train_step_dict()\n        log[\"train_step/xi\"] = self.xi\n        log[\"train_step/EBS\"] = self._last_ebs\n        return log\n\n    def _save_dict(self):\n        save = super()._save_dict()\n        save[\"min_ebs\"] = self.min_ebs\n        return save\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:55:45.383416Z","iopub.execute_input":"2025-06-11T10:55:45.383698Z","iopub.status.idle":"2025-06-11T10:55:50.685997Z","shell.execute_reply.started":"2025-06-11T10:55:45.383678Z","shell.execute_reply":"2025-06-11T10:55:50.685357Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# env = [\"FrozenLake\", \"CartPole\", \"MountainCar\", \"SeaQuest\", \"LunarLander\"][3]\nenv = \"MountainCar\"\nprint(f\"{env} is selected.\")\n\nbase_agent_config = {\n    **ENVS[env][\"env\"],\n    \"default_batch_size\": 128,\n    \"gamma\": 0.99,\n    \"learning_rate\": 3e-4,\n    \"replay_buffer_capacity\":100_000,\n    \"tau\": 5e-3,\n    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"gradient_norm_clip\": 10.0,\n    \"start_training_after\": 1000,\n    \"normalize_rewards\": False,\n    \"scale_rewards\": None\n}\n\nbase_run_config = {\n    **ENVS[env][\"run\"],\n    \"learn_every\": 1,  # Apply learning every n steps of rollout\n    \"eval_every\": 10_000,  # Evaluate model approximately every n steps\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:41:43.872685Z","iopub.execute_input":"2025-06-11T08:41:43.873263Z","iopub.status.idle":"2025-06-11T08:41:43.878218Z","shell.execute_reply.started":"2025-06-11T08:41:43.873240Z","shell.execute_reply":"2025-06-11T08:41:43.877458Z"}},"outputs":[{"name":"stdout","text":"MountainCar is selected.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"eps_greedy_config = {\n    **base_agent_config,\n    \"eps_decay\": 0.9999,\n    \"eps_min\": 0.01,\n    \"epsilon\": 1.0,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:41:46.436077Z","iopub.execute_input":"2025-06-11T08:41:46.436787Z","iopub.status.idle":"2025-06-11T08:41:46.440173Z","shell.execute_reply.started":"2025-06-11T08:41:46.436762Z","shell.execute_reply":"2025-06-11T08:41:46.439620Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"bootstrap_dqn_config = {\n    **eps_greedy_config,\n    \"k\": 5,\n    \"bernoulli_p\": 1,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:41:47.799052Z","iopub.execute_input":"2025-06-11T08:41:47.799286Z","iopub.status.idle":"2025-06-11T08:41:47.802679Z","shell.execute_reply.started":"2025-06-11T08:41:47.799268Z","shell.execute_reply":"2025-06-11T08:41:47.802066Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"rpf_bootstrap_dqn_config = {\n    **bootstrap_dqn_config,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:41:49.547823Z","iopub.execute_input":"2025-06-11T08:41:49.548402Z","iopub.status.idle":"2025-06-11T08:41:49.551686Z","shell.execute_reply.started":"2025-06-11T08:41:49.548380Z","shell.execute_reply":"2025-06-11T08:41:49.551045Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"ue_bootstrap_dqn_config = {\n    **rpf_bootstrap_dqn_config,\n    \"xi\": 0.1,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:41:51.044463Z","iopub.execute_input":"2025-06-11T08:41:51.044680Z","iopub.status.idle":"2025-06-11T08:41:51.048305Z","shell.execute_reply.started":"2025-06-11T08:41:51.044666Z","shell.execute_reply":"2025-06-11T08:41:51.047698Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"### Epsilon Greedy DQN","metadata":{}},{"cell_type":"code","source":"import wandb\nprint(wandb.__version__)\n!pip show wandb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T20:46:20.783867Z","iopub.execute_input":"2025-06-10T20:46:20.784117Z","iopub.status.idle":"2025-06-10T20:46:27.854957Z","shell.execute_reply.started":"2025-06-10T20:46:20.784094Z","shell.execute_reply":"2025-06-10T20:46:27.854206Z"}},"outputs":[{"name":"stdout","text":"0.19.9\nName: wandb\nVersion: 0.19.11\nSummary: A CLI and library for interacting with the Weights & Biases API.\nHome-page: \nAuthor: \nAuthor-email: Weights & Biases <support@wandb.com>\nLicense: MIT License\n\nCopyright (c) 2021 Weights and Biases, Inc.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: click, docker-pycreds, gitpython, platformdirs, protobuf, psutil, pydantic, pyyaml, requests, sentry-sdk, setproctitle, setuptools, typing-extensions\nRequired-by: main\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"eps_greedy\",\n    \"config\": {**eps_greedy_config, **base_run_config, \"machine\": get_machine()},\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"eps_greedy\"],\n}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\neps_greedy_dqn_agent = EpsGreedyDQNAgent(wandb_run=wandb_run, **eps_greedy_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T20:46:29.939743Z","iopub.execute_input":"2025-06-10T20:46:29.940070Z","iopub.status.idle":"2025-06-10T20:46:42.397493Z","shell.execute_reply.started":"2025-06-10T20:46:29.940041Z","shell.execute_reply":"2025-06-10T20:46:42.396454Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>████▅▅▃▂▂▁</td></tr><tr><td>eval_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_episode/sum_reward</td><td>▁▁▁▁▄▄▆▇▇█</td></tr><tr><td>train_episode/episode_length</td><td>█████▆█▆▆▆▃▆▅▅▅▁▅▅▂▁▂▂▂▂▂▂▄▂▄▄▂▅▄▄▂▂▄▂▂▄</td></tr><tr><td>train_episode/mean_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▅▅▆▇█</td></tr><tr><td>train_episode/mean_return</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>train_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_episode/sum_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▂▃▅▄▆▅▆▅█▆</td></tr><tr><td>train_episode/sum_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▆▄▁█▁▃▄▁▄▄█▄█▄▇▇▇▇▇█▇▅▆▇▇▇▅▇▅</td></tr><tr><td>train_episode/var_return</td><td>▁▁▁▁▁▁▁▁▂▂▃▃▃▃▄▄▅▆▆▆▆▇▇▇▇▇██████████████</td></tr><tr><td>train_step/epsilon</td><td>██▇▅▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step/grad_norm</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▂▂▃▃▄█▅████████████████████</td></tr><tr><td>train_step/loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▁▄▅▂▂▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>89</td></tr><tr><td>eval_episode/mean_reward</td><td>-1</td></tr><tr><td>eval_episode/sum_reward</td><td>-89</td></tr><tr><td>train_episode/episode_length</td><td>85</td></tr><tr><td>train_episode/mean_loss</td><td>56.71796</td></tr><tr><td>train_episode/mean_return</td><td>-73.93114</td></tr><tr><td>train_episode/mean_reward</td><td>-1</td></tr><tr><td>train_episode/sum_loss</td><td>4821.0266</td></tr><tr><td>train_episode/sum_reward</td><td>-85</td></tr><tr><td>train_episode/var_return</td><td>95.34375</td></tr><tr><td>train_step/epsilon</td><td>0.01</td></tr><tr><td>train_step/grad_norm</td><td>10.0</td></tr><tr><td>train_step/loss</td><td>13.0731</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">eps_greedy</strong> at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/0xqll0fj' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/0xqll0fj</a><br> View project at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a><br>Synced 5 W&B file(s), 10 media file(s), 8 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250610_203208-0xqll0fj/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250610_204629-a0phrrxy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/a0phrrxy' target=\"_blank\">eps_greedy</a></strong> to <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/a0phrrxy' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/a0phrrxy</a>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\ntry:\n    eps_greedy_dqn_agent.train(**base_run_config)\n    wandb_run.finish()\nexcept KeyboardInterrupt:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T20:46:46.906752Z","iopub.execute_input":"2025-06-10T20:46:46.907063Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/tmp/ipykernel_35/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/tmp/ipykernel_35/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### Bootstrap DQN","metadata":{}},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"bootstrap\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:45:17.096407Z","iopub.execute_input":"2025-06-11T05:45:17.096709Z","iopub.status.idle":"2025-06-11T05:45:28.457622Z","shell.execute_reply.started":"2025-06-11T05:45:17.096687Z","shell.execute_reply":"2025-06-11T05:45:28.456776Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250611_054517-dgri0at3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/dgri0at3' target=\"_blank\">bootstrap</a></strong> to <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/dgri0at3' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/dgri0at3</a>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"\nprint(wandb_config)\nbootstrap_dqn_agent = BootstrapDQNAgent(wandb_run=wandb_run, **bootstrap_dqn_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:45:34.056605Z","iopub.execute_input":"2025-06-11T05:45:34.056903Z","iopub.status.idle":"2025-06-11T05:45:39.392503Z","shell.execute_reply.started":"2025-06-11T05:45:34.056882Z","shell.execute_reply":"2025-06-11T05:45:39.391663Z"}},"outputs":[{"name":"stdout","text":"{'project': 'Asemaneh-Nafe-DQN-EXPLORE-HW', 'name': 'bootstrap', 'save_code': True, 'tags': ['dqn', 'bootstrap'], 'config': {'env_name': 'MountainCar-v0', 'env_config': {}, 'seed': 43, 'default_batch_size': 128, 'gamma': 0.99, 'learning_rate': 0.0003, 'replay_buffer_capacity': 100000, 'tau': 0.005, 'device': 'cuda', 'gradient_norm_clip': 10.0, 'start_training_after': 1000, 'normalize_rewards': False, 'scale_rewards': None, 'eps_decay': 0.9999, 'eps_min': 0.01, 'epsilon': 1.0, 'k': 5, 'bernoulli_p': 1, 'max_episodes': 100000, 'max_steps': 300000, 'max_steps_per_episode': 100000, 'max_time': 9000.0, 'learn_every': 1, 'eval_every': 10000, 'machine': 'Google Colab'}}\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\ntry:\n    bootstrap_dqn_agent.train(**base_run_config)\n    wandb_run.finish()\nexcept KeyboardInterrupt:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:45:44.671881Z","iopub.execute_input":"2025-06-11T05:45:44.672156Z","iopub.status.idle":"2025-06-11T07:20:20.145408Z","shell.execute_reply.started":"2025-06-11T05:45:44.672137Z","shell.execute_reply":"2025-06-11T07:20:20.144421Z"}},"outputs":[{"name":"stdout","text":"episode: 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 150\nepisode: 1050\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1250\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1300\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1350\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1400\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1450\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1500\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1550\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1600\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1650\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1700\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1750\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1800\nTrained for 300000 steps.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>█▃▅██▅▅▁▅▆▅▅▁▇▇█▇▇▇▇▆▇█▇██████</td></tr><tr><td>eval_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_episode/sum_reward</td><td>▁▆▄▁▁▄▄█▄▃▄▄█▂▂▁▂▂▂▂▃▂▁▂▁▁▁▁▁▁</td></tr><tr><td>train_episode/current_head</td><td>█▅▃▅▃▅▃▅█▃▁█▁▅▃█▁▅▆▆▃█▃▅▆▅▁▁▆▆▃█▃▁▆▆▆▆▅▃</td></tr><tr><td>train_episode/episode_length</td><td>██▂█████▁▆▅▅▆▁▅▁▅▁▂▅▅▇▇██▇▇▇▇▇▇█████████</td></tr><tr><td>train_episode/mean_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▅▅▆▅▅▆▆██</td></tr><tr><td>train_episode/mean_return</td><td>▁▁▁▁▃▆▅▅▅▅▆▇▇▇▇▇▇▇▇▇████████▇▇▆▆▆▆▆▆▆▆▆▅</td></tr><tr><td>train_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_episode/sum_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train_episode/sum_reward</td><td>▂▁▁▁▆▁▁▄▆▆▄██▇█▄▃▄▇█▂▂▁▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_episode/var_return</td><td>▁▁▆█▇██████████████████████▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train_step/epsilon</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step/grad_norm</td><td>▁▂▇█████████████████████████████████████</td></tr><tr><td>train_step/loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▃▂▂▂▁█▄▄▆▃▃█▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>200</td></tr><tr><td>eval_episode/mean_reward</td><td>-1</td></tr><tr><td>eval_episode/sum_reward</td><td>-200</td></tr><tr><td>train_episode/current_head</td><td>3</td></tr><tr><td>train_episode/episode_length</td><td>55</td></tr><tr><td>train_episode/mean_loss</td><td>20575.88601</td></tr><tr><td>train_episode/mean_return</td><td>-78.92664</td></tr><tr><td>train_episode/mean_reward</td><td>-1</td></tr><tr><td>train_episode/sum_loss</td><td>1131673.73047</td></tr><tr><td>train_episode/sum_reward</td><td>-55</td></tr><tr><td>train_episode/var_return</td><td>93.05016</td></tr><tr><td>train_step/epsilon</td><td>1</td></tr><tr><td>train_step/grad_norm</td><td>10.0</td></tr><tr><td>train_step/loss</td><td>10269.25</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">bootstrap</strong> at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/dgri0at3' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/dgri0at3</a><br> View project at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a><br>Synced 5 W&B file(s), 30 media file(s), 7 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250611_054517-dgri0at3/logs</code>"},"metadata":{}}],"execution_count":56},{"cell_type":"markdown","source":"### Bootstrap DQN with Randomized Prior Function","metadata":{}},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"randomized_prior\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"rpf_bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**rpf_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\nrpf_bootstrap_dqn_agent = RPFBootstrapDQNAgent(wandb_run=wandb_run, **rpf_bootstrap_dqn_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:42:07.509311Z","iopub.execute_input":"2025-06-11T08:42:07.510103Z","iopub.status.idle":"2025-06-11T08:42:27.770802Z","shell.execute_reply.started":"2025-06-11T08:42:07.510078Z","shell.execute_reply":"2025-06-11T08:42:27.770264Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masemanehnafe\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250611_084213-d26ha1tc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/d26ha1tc' target=\"_blank\">randomized_prior</a></strong> to <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/d26ha1tc' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/d26ha1tc</a>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"print(wandb_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:42:27.771964Z","iopub.execute_input":"2025-06-11T08:42:27.772210Z","iopub.status.idle":"2025-06-11T08:42:32.983931Z","shell.execute_reply.started":"2025-06-11T08:42:27.772184Z","shell.execute_reply":"2025-06-11T08:42:32.983361Z"}},"outputs":[{"name":"stdout","text":"{'project': 'Asemaneh-Nafe-DQN-EXPLORE-HW', 'name': 'randomized_prior', 'save_code': True, 'tags': ['dqn', 'rpf_bootstrap'], 'config': {'env_name': 'MountainCar-v0', 'env_config': {}, 'seed': 43, 'default_batch_size': 128, 'gamma': 0.99, 'learning_rate': 0.0003, 'replay_buffer_capacity': 100000, 'tau': 0.005, 'device': 'cuda', 'gradient_norm_clip': 10.0, 'start_training_after': 1000, 'normalize_rewards': False, 'scale_rewards': None, 'eps_decay': 0.9999, 'eps_min': 0.01, 'epsilon': 1.0, 'k': 5, 'bernoulli_p': 1, 'max_episodes': 100000, 'max_steps': 300000, 'max_steps_per_episode': 100000, 'max_time': 9000.0, 'learn_every': 1, 'eval_every': 10000, 'machine': 'Kaggle'}}\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\ntry:\n    rpf_bootstrap_dqn_agent.train(**base_run_config)\n    wandb_run.finish()\nexcept KeyboardInterrupt:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:42:34.516775Z","iopub.execute_input":"2025-06-11T08:42:34.517514Z","iopub.status.idle":"2025-06-11T10:09:01.593693Z","shell.execute_reply.started":"2025-06-11T08:42:34.517486Z","shell.execute_reply":"2025-06-11T10:09:01.593103Z"}},"outputs":[{"name":"stdout","text":"episode: 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\nerror: XDG_RUNTIME_DIR not set in the environment.\n","output_type":"stream"},{"name":"stdout","text":"episode: 50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 250\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 300\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 350\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 400\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 450\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 500\nepisode: 550\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 600\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 650\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 700\nepisode: 750\nepisode: 800\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 850\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 900\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 950\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1050\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1250\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1300\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1350\nepisode: 1400\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1450\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1500\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1550\nepisode: 1600\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1650\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1700\nTrained for 300000 steps.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>██████▃▃▃███▆███████▇▄▇▇█▁▁▆██</td></tr><tr><td>eval_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_episode/sum_reward</td><td>▁▁▁▁▁▁▆▆▆▁▁▁▃▁▁▁▁▁▁▁▂▅▂▂▁██▃▁▁</td></tr><tr><td>train_episode/current_head</td><td>█▃█▃▆▆▆▆▅▆▅▃▅▅▅▃▅▃▆▆▁▆█▆▁▆██▁█▃▃▃▅▆▆▅██▅</td></tr><tr><td>train_episode/episode_length</td><td>██████████▁▆▅██▁▂▁▆█████▆▆█▇▇▇▇████▆▂▆▆▇</td></tr><tr><td>train_episode/mean_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▆█</td></tr><tr><td>train_episode/mean_return</td><td>▁▁▁▁▁▁▁▁▁▁▆▇▇▆▆▆▇██▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_episode/sum_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▃▄▅█</td></tr><tr><td>train_episode/sum_reward</td><td>▁▁▁▁▁▁▁▃▆▇▁▁█▆█▄▃▄█▃▁▁▁▁▁▁▁▁▂▁▂▂▂▁▂██▃▃▂</td></tr><tr><td>train_episode/var_return</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▄▇▇▇████▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇</td></tr><tr><td>train_step/epsilon</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step/grad_norm</td><td>▁▁▁▁▁▁▁▂▂▂▁▂▁▆███▇███▇█▇███████▇████████</td></tr><tr><td>train_step/loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▃▃█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>198</td></tr><tr><td>eval_episode/mean_reward</td><td>-1</td></tr><tr><td>eval_episode/sum_reward</td><td>-198</td></tr><tr><td>train_episode/current_head</td><td>1</td></tr><tr><td>train_episode/episode_length</td><td>27</td></tr><tr><td>train_episode/mean_loss</td><td>195.16475</td></tr><tr><td>train_episode/mean_return</td><td>-81.48244</td></tr><tr><td>train_episode/mean_reward</td><td>-1</td></tr><tr><td>train_episode/sum_loss</td><td>5269.44824</td></tr><tr><td>train_episode/sum_reward</td><td>-27</td></tr><tr><td>train_episode/var_return</td><td>70.75144</td></tr><tr><td>train_step/epsilon</td><td>1</td></tr><tr><td>train_step/grad_norm</td><td>10.0</td></tr><tr><td>train_step/loss</td><td>71.78954</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">randomized_prior</strong> at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/d26ha1tc' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/d26ha1tc</a><br> View project at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a><br>Synced 5 W&B file(s), 30 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250611_084213-d26ha1tc/logs</code>"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"### Uncertainty Estimation for Sample Efficient RPF Bootstrap DQN","metadata":{}},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"uncertainty_estimation\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"ue_bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**ue_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\nue_bootstrap_dqn_agent = UEBootstrapDQNAgent(wandb_run=wandb_run, **ue_bootstrap_dqn_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:56:00.821745Z","iopub.execute_input":"2025-06-11T10:56:00.822481Z","iopub.status.idle":"2025-06-11T10:56:14.551173Z","shell.execute_reply.started":"2025-06-11T10:56:00.822456Z","shell.execute_reply":"2025-06-11T10:56:14.550566Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_episode/current_head</td><td>▁▆█▁</td></tr><tr><td>train_episode/episode_length</td><td>▁▁▁▁</td></tr><tr><td>train_episode/mean_loss</td><td>▁▁▁▁</td></tr><tr><td>train_episode/mean_return</td><td>█▁▁▁</td></tr><tr><td>train_episode/mean_reward</td><td>▁▁▁▁</td></tr><tr><td>train_episode/sum_loss</td><td>▁▁▁▁</td></tr><tr><td>train_episode/sum_reward</td><td>▁▁▁▁</td></tr><tr><td>train_episode/var_return</td><td>█▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_episode/current_head</td><td>0</td></tr><tr><td>train_episode/episode_length</td><td>200</td></tr><tr><td>train_episode/mean_loss</td><td>0</td></tr><tr><td>train_episode/mean_return</td><td>-86.6021</td></tr><tr><td>train_episode/mean_reward</td><td>-1</td></tr><tr><td>train_episode/sum_loss</td><td>0</td></tr><tr><td>train_episode/sum_reward</td><td>-200</td></tr><tr><td>train_episode/var_return</td><td>0</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">uncertainty_estimation</strong> at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/544gd7rc' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/544gd7rc</a><br> View project at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a><br>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250611_105447-544gd7rc/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250611_105600-02ig5373</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/02ig5373' target=\"_blank\">uncertainty_estimation</a></strong> to <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/02ig5373' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/02ig5373</a>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nue_bootstrap_dqn_agent.train(**base_run_config)\nwandb_run.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:56:14.552109Z","iopub.execute_input":"2025-06-11T10:56:14.552311Z","iopub.status.idle":"2025-06-11T12:13:00.859549Z","shell.execute_reply.started":"2025-06-11T10:56:14.552287Z","shell.execute_reply":"2025-06-11T12:13:00.858814Z"}},"outputs":[{"name":"stdout","text":"episode: 0\nepisode: 50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 250\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 300\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 350\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 400\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 450\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 500\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 550\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 600\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 650\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 700\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 750\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 800\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 850\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 900\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 950\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1050\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1250\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1300\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1350\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1400\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1450\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1500\nTrained for 300000 steps.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_episode/sum_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_episode/current_head</td><td>▅▆▅▃██▆▃▅▅▆▃▃▁▅█▅▅██▁▃▁█▆▁▃▁▅▁▃▃██▁▅▁▆▆▆</td></tr><tr><td>train_episode/episode_length</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_episode/mean_loss</td><td>▁▁▅▅▆▆▆▆▆▇▇▆█▇▇▇▇█▇█▇▇█▆▅▅▅▄▄▃▃▃▃▃▃▄▄▅▅▄</td></tr><tr><td>train_episode/mean_return</td><td>▁▁▁▁▁▁▁▁▁▁▅▇▇▆██▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃</td></tr><tr><td>train_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_episode/sum_loss</td><td>▁▁▂▅▆▆▆▇▇█▆▆█▇▇▆▇▆▇▆▆▆▇▄▄▃▃▂▂▂▃▃▃▃▄▅▅▄▄▅</td></tr><tr><td>train_episode/sum_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_episode/var_return</td><td>▁▁▁▁▁▁▁▁▅▇▇▇███▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>train_step/EBS</td><td>███████████████▇▇▇▇█████▇▇▇▇▇▅▆▆▃▂▁▅▅▅▅▃</td></tr><tr><td>train_step/epsilon</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step/grad_norm</td><td>▁▂▆██▁▅█▇▂███▅███▄██▅████████████▅██████</td></tr><tr><td>train_step/loss</td><td>▁▁▁▁▁▁▄▄▁█▅▁▁▁▁▁▅▁▁▇▁▄▅▁▁▃▆▂▁▁▁▂▁▄▁▃▄▄▂▃</td></tr><tr><td>train_step/xi</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>200</td></tr><tr><td>eval_episode/mean_reward</td><td>-1</td></tr><tr><td>eval_episode/sum_reward</td><td>-200</td></tr><tr><td>train_episode/current_head</td><td>1</td></tr><tr><td>train_episode/episode_length</td><td>133</td></tr><tr><td>train_episode/mean_loss</td><td>12.61621</td></tr><tr><td>train_episode/mean_return</td><td>-86.58686</td></tr><tr><td>train_episode/mean_reward</td><td>-1</td></tr><tr><td>train_episode/sum_loss</td><td>1677.95607</td></tr><tr><td>train_episode/sum_reward</td><td>-133</td></tr><tr><td>train_episode/var_return</td><td>0.11723</td></tr><tr><td>train_step/EBS</td><td>123.71907</td></tr><tr><td>train_step/epsilon</td><td>1</td></tr><tr><td>train_step/grad_norm</td><td>10.0</td></tr><tr><td>train_step/loss</td><td>0.10779</td></tr><tr><td>train_step/xi</td><td>0.1</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">uncertainty_estimation</strong> at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/02ig5373' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/02ig5373</a><br> View project at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a><br>Synced 5 W&B file(s), 30 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250611_105600-02ig5373/logs</code>"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"","metadata":{}}]}