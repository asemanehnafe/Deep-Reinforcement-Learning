{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"FIRST_NAME = \"Asemaneh\" # replace with your first name\nLAST_NAME = \"Nafe\" # replace with your last name\nSTUDENT_ID = 400105285 # replace with your student id\nWANDB_ID = \"asemanehnafe\" # replace with your wandb username\nPROJECT_NAME = f\"{FIRST_NAME}-{LAST_NAME}-DQN-EXPLORE-HW\"\nprint(f\"Project name: {PROJECT_NAME}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:56:58.768639Z","iopub.execute_input":"2025-06-11T07:56:58.768966Z","iopub.status.idle":"2025-06-11T07:56:58.775027Z","shell.execute_reply.started":"2025-06-11T07:56:58.768943Z","shell.execute_reply":"2025-06-11T07:56:58.773960Z"}},"outputs":[{"name":"stdout","text":"Project name: Asemaneh-Nafe-DQN-EXPLORE-HW\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(f\"Check my results at https://wandb.ai/{WANDB_ID}/{PROJECT_NAME}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:57:00.975029Z","iopub.execute_input":"2025-06-11T07:57:00.975316Z","iopub.status.idle":"2025-06-11T07:57:00.979926Z","shell.execute_reply.started":"2025-06-11T07:57:00.975293Z","shell.execute_reply":"2025-06-11T07:57:00.978895Z"}},"outputs":[{"name":"stdout","text":"Check my results at https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Set DEBUG to True if you are still implementing the code and debugging\n# and don't want to make your wandb dashboard messy.\n# set DEBUG to False if you are almost done with the implementation\n# and want check performance and compare hyperparameters and models\nDEBUG = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:57:01.967516Z","iopub.execute_input":"2025-06-11T07:57:01.967899Z","iopub.status.idle":"2025-06-11T07:57:01.971924Z","shell.execute_reply.started":"2025-06-11T07:57:01.967874Z","shell.execute_reply":"2025-06-11T07:57:01.971046Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!apt install build-essential python3-dev\n!git clone https://github.com/DeepRLCourse/Homework-10.git\n%pip install swig\n%pip install \"Homework-10/BootstrapDQN\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:57:03.015326Z","iopub.execute_input":"2025-06-11T07:57:03.015603Z","iopub.status.idle":"2025-06-11T08:00:12.195725Z","shell.execute_reply.started":"2025-06-11T07:57:03.015581Z","shell.execute_reply":"2025-06-11T08:00:12.193871Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nbuild-essential is already the newest version (12.9ubuntu3).\npython3-dev is already the newest version (3.10.6-1~22.04.1).\npython3-dev set to manually installed.\n0 upgraded, 0 newly installed, 0 to remove and 87 not upgraded.\nCloning into 'Homework-10'...\nremote: Enumerating objects: 111, done.\u001b[K\nremote: Counting objects: 100% (111/111), done.\u001b[K\nremote: Compressing objects: 100% (67/67), done.\u001b[K\nremote: Total 111 (delta 37), reused 108 (delta 34), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (111/111), 1.14 MiB | 19.12 MiB/s, done.\nResolving deltas: 100% (37/37), done.\nCollecting swig\n  Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\nDownloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: swig\nSuccessfully installed swig-4.3.1\nNote: you may need to restart the kernel to use updated packages.\nProcessing ./Homework-10/BootstrapDQN\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: ale-py<=0.11.0,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (0.10.2)\nCollecting dotenv>=0.9.9 (from main==0.1.0)\n  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\nCollecting gymnasium>=1.1.1 (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0)\n  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting ipykernel>=6.29.5 (from main==0.1.0)\n  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: nbformat>=5.10.4 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (5.10.4)\nRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (1.26.4)\nCollecting pip>=25.0.1 (from main==0.1.0)\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: swig>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (4.3.1)\nRequirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (2.6.0+cu124)\nRequirement already satisfied: wandb>=0.19.9 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (0.19.9)\nCollecting python-dotenv (from dotenv>=0.9.9->main==0.1.0)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (3.1.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (4.13.2)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (0.0.4)\nCollecting box2d-py==2.3.5 (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0)\n  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (2.6.1)\nRequirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (0.2.2)\nRequirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (1.8.0)\nRequirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (7.34.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (8.6.3)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (5.7.2)\nRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (0.1.7)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (1.6.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (7.0.0)\nRequirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (24.0.1)\nRequirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (6.4.2)\nRequirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (5.7.1)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.10.4->main==0.1.0) (2.21.1)\nRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.10.4->main==0.1.0) (4.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->main==0.1.0) (1.3.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (3.20.3)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.11.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (75.2.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.19.9->main==0.1.0) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.19.9->main==0.1.0) (4.0.12)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (3.0.50)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (0.24.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.29.5->main==0.1.0) (2.9.0.post0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->main==0.1.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->main==0.1.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->main==0.1.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.19.9->main==0.1.0) (5.0.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.2.13)\nDownloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\nDownloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nBuilding wheels for collected packages: main, box2d-py\n  Building wheel for main (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for main: filename=main-0.1.0-py3-none-any.whl size=11117 sha256=e08422f5b6f81ca413ae35877146e6da6067b35e184129cf46c6743a4f54331c\n  Stored in directory: /tmp/pip-ephem-wheel-cache-enzmkask/wheels/4f/16/b7/f0afc1a4a4574831edbabf07feb162c98e9e62978951f878e1\n  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379375 sha256=426adfaf7d98b2733a208eecc16e1acdf4c321fcf5580c660940e79f3a9b2d7c\n  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\nSuccessfully built main box2d-py\nInstalling collected packages: box2d-py, python-dotenv, pip, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dotenv, nvidia-cusolver-cu12, ipykernel, gymnasium, main\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: ipykernel\n    Found existing installation: ipykernel 6.17.1\n    Uninstalling ipykernel-6.17.1:\n      Successfully uninstalled ipykernel-6.17.1\n  Attempting uninstall: gymnasium\n    Found existing installation: gymnasium 0.29.0\n    Uninstalling gymnasium-0.29.0:\n      Successfully uninstalled gymnasium-0.29.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.11 requires gymnasium==0.29.0, but you have gymnasium 1.1.1 which is incompatible.\nstable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.1.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires ipykernel==6.17.1, but you have ipykernel 6.29.5 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed box2d-py-2.3.5 dotenv-0.9.9 gymnasium-1.1.1 ipykernel-6.29.5 main-0.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pip-25.1.1 python-dotenv-1.1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\nfrom bootstrapdqn import ReplayBuffer, BaseDQNAgent, get_machine, set_wandb_key_form_secrets, envs\nimport torch\nfrom torch import nn\nimport wandb\nimport random\nimport gymnasium as gym\nimport ale_py\nimport time\n\ngym.register_envs(ale_py)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:01:23.167767Z","iopub.execute_input":"2025-06-11T08:01:23.168359Z","iopub.status.idle":"2025-06-11T08:01:23.173550Z","shell.execute_reply.started":"2025-06-11T08:01:23.168334Z","shell.execute_reply":"2025-06-11T08:01:23.172498Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\nTA = True if WANDB_ID == \"alireza9\" else False\nSAVE_CODE = False if TA else True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:01:25.239369Z","iopub.execute_input":"2025-06-11T08:01:25.240067Z","iopub.status.idle":"2025-06-11T08:01:25.244202Z","shell.execute_reply.started":"2025-06-11T08:01:25.240037Z","shell.execute_reply":"2025-06-11T08:01:25.243299Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(SAVE_CODE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:01:27.425036Z","iopub.execute_input":"2025-06-11T08:01:27.425370Z","iopub.status.idle":"2025-06-11T08:01:27.430292Z","shell.execute_reply.started":"2025-06-11T08:01:27.425348Z","shell.execute_reply":"2025-06-11T08:01:27.429273Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\n# IF YOU CHANGE ANYTHING ABOUT ENVIRONMENTS AND THEIR RUN CONFIGS, YOUR CODE WILL NOT BE GRADED\nfrom pprint import pprint\nENVS = envs()\npprint(ENVS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:01:29.007805Z","iopub.execute_input":"2025-06-11T08:01:29.008159Z","iopub.status.idle":"2025-06-11T08:01:29.014519Z","shell.execute_reply.started":"2025-06-11T08:01:29.008136Z","shell.execute_reply":"2025-06-11T08:01:29.013401Z"}},"outputs":[{"name":"stdout","text":"{'CartPole': {'env': {'env_config': {}, 'env_name': 'CartPole-v1', 'seed': 43},\n              'run': {'max_episodes': 1000,\n                      'max_steps': 50000,\n                      'max_steps_per_episode': 100000,\n                      'max_time': 720.0}},\n 'FrozenLake': {'env': {'env_config': {'p': 0.87, 'size': 14},\n                        'env_name': 'FrozenLake-v1',\n                        'seed': 42},\n                'run': {'max_episodes': 1000000,\n                        'max_steps': 1000000,\n                        'max_steps_per_episode': 100000,\n                        'max_time': 14400}},\n 'LunarLander': {'env': {'env_config': {},\n                         'env_name': 'LunarLander-v3',\n                         'seed': 43},\n                 'run': {'max_episodes': 100000,\n                         'max_steps': 200000,\n                         'max_steps_per_episode': 100000,\n                         'max_time': 7200}},\n 'MountainCar': {'env': {'env_config': {},\n                         'env_name': 'MountainCar-v0',\n                         'seed': 43},\n                 'run': {'max_episodes': 100000,\n                         'max_steps': 300000,\n                         'max_steps_per_episode': 100000,\n                         'max_time': 9000.0}},\n 'SeaQuest': {'env': {'env_config': {},\n                      'env_name': 'Seaquest-ramNoFrameskip-v4',\n                      'seed': 43},\n              'run': {'max_episodes': 1000000,\n                      'max_steps': 2000000,\n                      'max_steps_per_episode': 1000000,\n                      'max_time': 28800}}}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"if not DEBUG:\n    set_wandb_key_form_secrets()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:01:32.326979Z","iopub.execute_input":"2025-06-11T08:01:32.327690Z","iopub.status.idle":"2025-06-11T08:01:32.505494Z","shell.execute_reply.started":"2025-06-11T08:01:32.327660Z","shell.execute_reply":"2025-06-11T08:01:32.504533Z"}},"outputs":[{"name":"stdout","text":"your machine is detected as Kaggle\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"class EpsGreedyDQNAgent(BaseDQNAgent):\n    \"\"\"\n    Epsilon-greedy DQN agent.\n    \"\"\"\n\n    def __init__(self, epsilon: float = 0.1, eps_decay: float = 0.999, eps_min: float = 0.01, **kwargs):\n        super().__init__(**kwargs)\n        self.epsilon = epsilon\n        self.eps_decay = eps_decay\n        self.eps_min = eps_min\n\n    def _decay_eps(self):\n        \"\"\"\n        Decay the epsilon value.\n        \"\"\"\n        self.epsilon = max(self.epsilon * self.eps_decay, self.eps_min)\n\n    def _create_replay_buffer(self, max_size=1000000):\n        self.replay_buffer = ReplayBuffer(\n            [\n                (\"state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"action\", (), torch.int64),\n                (\"reward\", (), torch.float32),\n                (\"next_state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"done\", (), torch.float32),\n            ],\n            max_size=max_size,\n            device=self.device,\n        )\n\n    def _create_network(self):\n        self.q_network = nn.Sequential(\n            nn.Linear(self.env.observation_space.shape[0], 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, self.env.action_space.n),\n        ).to(self.device)\n        self.q_network.apply(\n            lambda m: torch.nn.init.orthogonal_(m.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n            if isinstance(m, nn.Linear)\n            else None\n        )\n        self.target_network = nn.Sequential(\n            nn.Linear(self.env.observation_space.shape[0], 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, self.env.action_space.n),\n        ).to(self.device)\n\n    def _compute_loss(self, batch):\n        \"\"\"\n        Compute the loss for the DQN agent.\n        \"\"\"\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n\n        q_values = self.q_network(states).gather(1, actions.unsqueeze(1)).squeeze()\n        next_q_values = self.target_network(next_states).max(1)[0]\n        expected_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n\n        loss = nn.SmoothL1Loss()(q_values, expected_q_values)\n        return loss\n\n    def _act_in_training(self, state):\n        \"\"\"\n        Select an action during training.\n        \"\"\"\n        self._decay_eps()\n        if torch.rand(1).item() < self.epsilon:\n            return self.env.action_space.sample()\n        else:\n            with torch.no_grad():\n                q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n                return q_values.argmax().item()\n\n    def _act_in_eval(self, state):\n        \"\"\"\n        Select an action during evaluation.\n        \"\"\"\n        with torch.no_grad():\n            q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n            return q_values.argmax().item()\n\n    def _wandb_train_step_dict(self):\n        log_dict = super()._wandb_train_step_dict()\n        log_dict[\"train_step/epsilon\"] = self.epsilon\n        return log_dict\n\n    def _save_dict(self):\n        save_dict = super()._save_dict()\n        save_dict[\"epsilon\"] = self.epsilon\n        save_dict[\"eps_decay\"] = self.eps_decay\n        save_dict[\"eps_min\"] = self.eps_min\n        return save_dict\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:01:34.012678Z","iopub.execute_input":"2025-06-11T08:01:34.013016Z","iopub.status.idle":"2025-06-11T08:01:34.028544Z","shell.execute_reply.started":"2025-06-11T08:01:34.012993Z","shell.execute_reply":"2025-06-11T08:01:34.027687Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class MultiHeadQNet(nn.Module):\n    def __init__(self, input_dim, output_dim, k):\n        super().__init__()\n        self.k = k\n        self.shared = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU()\n        )\n        self.heads = nn.ModuleList([\n            nn.Linear(256, output_dim) for _ in range(k)\n        ])\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            torch.nn.init.orthogonal_(m.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n\n    def forward(self, x):\n        shared_out = self.shared(x)\n        return torch.stack([head(shared_out) for head in self.heads], dim=1)  # [B, K, A]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:01:37.337172Z","iopub.execute_input":"2025-06-11T08:01:37.337482Z","iopub.status.idle":"2025-06-11T08:01:37.345097Z","shell.execute_reply.started":"2025-06-11T08:01:37.337460Z","shell.execute_reply":"2025-06-11T08:01:37.343946Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class BootstrapDQNAgent(EpsGreedyDQNAgent):\n    def __init__(self, k: int = 10, bernoulli_p: float = 0.5, **kwargs):\n        self.k = k\n        self.bernoulli_p = bernoulli_p\n        self.current_head = 0\n        super().__init__(**kwargs)\n\n    def _create_network(self):\n        obs_dim = self.env.observation_space.shape[0]\n        action_dim = self.env.action_space.n\n\n        self.q_network = MultiHeadQNet(obs_dim, action_dim, self.k).to(self.device)\n        self.target_network = MultiHeadQNet(obs_dim, action_dim, self.k).to(self.device)\n\n    def _create_replay_buffer(self, max_size=1000000):\n        self.replay_buffer = ReplayBuffer(\n            [\n                (\"state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"action\", (), torch.int64),\n                (\"reward\", (), torch.float32),\n                (\"next_state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"done\", (), torch.float32),\n                (\"mask\", (self.k,), torch.bool),  # additional field for head masking\n            ],\n            max_size=max_size,\n            device=self.device,\n        )\n\n    def _preprocess_add(self, state, action, reward, next_state, done):\n        state = torch.as_tensor(state, dtype=torch.float32, device=self.device)\n        action = torch.as_tensor(action, dtype=torch.int64, device=self.device)\n        reward = torch.as_tensor(reward, dtype=torch.float32, device=self.device)\n        next_state = torch.as_tensor(next_state, dtype=torch.float32, device=self.device)\n        done = torch.as_tensor(done, dtype=torch.float32, device=self.device)\n    \n        mask = torch.bernoulli(torch.full((self.k,), self.bernoulli_p, dtype=torch.float32, device=self.device)).bool()\n    \n        return {\n            \"state\": state,\n            \"action\": action,\n            \"reward\": reward,\n            \"next_state\": next_state,\n            \"done\": done,\n            \"mask\": mask,\n        }\n\n\n    def _compute_loss(self, batch):\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        masks = batch[\"mask\"]  # [B, K]\n\n        all_q = self.q_network(states)          # [B, K, A]\n        all_q_target = self.target_network(next_states)  # [B, K, A]\n\n        loss = 0\n        for head in range(self.k):\n            head_mask = masks[:, head]\n            if head_mask.sum() == 0:\n                continue  # skip if no samples for this head\n\n            q = all_q[head_mask, head, :].gather(1, actions[head_mask].unsqueeze(1)).squeeze()\n            next_q = all_q_target[head_mask, head, :].max(1)[0]\n            target = rewards[head_mask] + (1 - dones[head_mask]) * self.gamma * next_q\n            loss += nn.SmoothL1Loss()(q, target)\n\n        return loss / self.k\n\n    def _episode(self):\n        super()._episode()\n        self.current_head = random.randint(0, self.k - 1)\n\n    def _act_in_training(self, state):\n        # self._decay_eps()\n        # if torch.rand(1).item() < self.epsilon:\n        #     return self.env.action_space.sample()\n        # else:\n        with torch.no_grad():\n            state_tensor = torch.as_tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n            q_values = self.q_network(state_tensor)[0, self.current_head]\n            return q_values.argmax().item()\n\n    def _act_in_eval(self, state):\n        with torch.no_grad():\n            state_tensor = torch.as_tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n            q_values = self.q_network(state_tensor)[0].mean(dim=0)  # average over heads\n            return q_values.argmax().item()\n\n    def _wandb_train_episode_dict(self):\n        log_dict = super()._wandb_train_episode_dict()\n        log_dict[\"train_episode/current_head\"] = self.current_head\n        return log_dict\n\n    def _save_dict(self):\n        save_dict = super()._save_dict()\n        save_dict[\"k\"] = self.k\n        save_dict[\"bernoulli_p\"] = self.bernoulli_p\n        return save_dict\n    def train(\n        self,\n        max_episodes=10000,\n        max_steps_per_episode=5000,\n        max_steps=1000000,\n        max_time=4 * 60 * 60,\n        learn_every=10,\n        eval_every=10000,\n    ):\n        \"\"\"\n        Train the agent over multiple episodes, performing learning updates and periodic evaluations.\n        \"\"\"\n        start_time = time.time()\n        pre_evaluation_step = self._training_step\n        max_steps += self._training_step\n        finished = False\n\n        for episode in range(max_episodes):\n            if episode % 50 == 0:\n                print(f\"episode: {episode}\")\n            self.train_mode()\n            self.env.action_space.seed(random.randint(0, 1e32 - 1))\n            state, _ = self.env.reset(seed=random.randint(0, 1e32 - 1))\n            for step in range(max_steps_per_episode):\n                action = self.act(state)\n                next_state, reward, terminated, truncated, _ = self.env.step(action)\n                done = terminated or truncated\n\n                self._step(reward)\n                self.add_experience(state, action, reward, next_state, done)\n\n                state = next_state\n\n                if self._total_steps % learn_every == 0:\n                    self.learn()\n\n                if done:\n                    break\n\n                if self._training_step >= max_steps or time.time() - start_time >= max_time:\n                    finished = True\n                    break\n\n            self._episode()\n\n            if self._training_step - pre_evaluation_step >= eval_every:\n                self.evaluate()\n                pre_evaluation_step = self._training_step\n\n            if finished:\n                self.evaluate()\n                print(f\"Trained for {self._training_step} steps.\")\n                break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:02:46.137309Z","iopub.execute_input":"2025-06-11T08:02:46.137680Z","iopub.status.idle":"2025-06-11T08:02:46.159038Z","shell.execute_reply.started":"2025-06-11T08:02:46.137655Z","shell.execute_reply":"2025-06-11T08:02:46.158054Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class PriorMultiHeadQNet(nn.Module):\n    def __init__(self, input_dim, output_dim, k):\n        super().__init__()\n        self.k = k\n        self.shared = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n        )\n        self.heads = nn.ModuleList([\n            nn.Linear(64, output_dim) for _ in range(k)\n        ])\n        self._freeze_weights()\n\n    def _freeze_weights(self):\n        for param in self.parameters():\n            param.requires_grad = False  # Ensure prior is fixed\n\n    def forward(self, x):\n        shared_out = self.shared(x)\n        return torch.stack([head(shared_out) for head in self.heads], dim=1)  # [B, K, A]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:02:49.607165Z","iopub.execute_input":"2025-06-11T08:02:49.607491Z","iopub.status.idle":"2025-06-11T08:02:49.614443Z","shell.execute_reply.started":"2025-06-11T08:02:49.607467Z","shell.execute_reply":"2025-06-11T08:02:49.613447Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class RPFBootstrapDQNAgent(BootstrapDQNAgent):\n    def _create_network(self):\n        super()._create_network()\n\n        input_dim = self.env.observation_space.shape[0]\n        output_dim = self.env.action_space.n\n\n        self.prior_network = PriorMultiHeadQNet(input_dim, output_dim, self.k).to(self.device)\n\n    def _act_in_training(self, state):\n        # self._decay_eps()\n        # if torch.rand(1).item() < self.epsilon:\n        #     return self.env.action_space.sample()\n        # else:\n        with torch.no_grad():\n            state_tensor = torch.as_tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n            q = self.q_network(state_tensor)[0, self.current_head] + \\\n                self.prior_network(state_tensor)[0, self.current_head]\n            return q.argmax().item()\n\n    def _act_in_eval(self, state):\n        with torch.no_grad():\n            state_tensor = torch.as_tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n            q = self.q_network(state_tensor)\n            return q.mean(dim=1).squeeze().argmax().item()\n\n    def _compute_loss(self, batch):\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        masks = batch[\"mask\"]\n\n        all_q = self.q_network(states) + self.prior_network(states)              # [B, K, A]\n        all_q_target = self.target_network(next_states) + self.prior_network(next_states)\n\n        loss = 0\n        for head in range(self.k):\n            head_mask = masks[:, head]\n            if head_mask.sum() == 0:\n                continue\n\n            q = all_q[head_mask, head, :].gather(1, actions[head_mask].unsqueeze(1)).squeeze()\n            next_q = all_q_target[head_mask, head, :].max(1)[0]\n            target = rewards[head_mask] + (1 - dones[head_mask]) * self.gamma * next_q\n            loss += nn.SmoothL1Loss()(q, target)\n\n        return loss / self.k\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:02:51.416422Z","iopub.execute_input":"2025-06-11T08:02:51.416734Z","iopub.status.idle":"2025-06-11T08:02:51.427214Z","shell.execute_reply.started":"2025-06-11T08:02:51.416712Z","shell.execute_reply":"2025-06-11T08:02:51.425909Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class UEBootstrapDQNAgent(RPFBootstrapDQNAgent):\n    def __init__(self, min_ebs: float = 32, xi= None , **kwargs):\n        super().__init__(**kwargs)\n        self.min_ebs = min_ebs\n        self.xi = None  # Will be set dynamically\n\n    def _compute_loss(self, batch):\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        masks = batch[\"mask\"]  # [B, K]        losses = []\n        sigmas = []\n\n        for j in range(self.k):  # Each head\n            head_mask = masks[:, j]\n\n            if head_mask.sum() == 0:\n                continue  # skip if no samples for this head\n\n            # Q and Prior\n            q_values = self.q_network(states)[0, self.current_head]\n            prior = self.prior_network(states)[0, self.current_head]\n            q_plus_prior = q_values + prior\n\n            with torch.no_grad():\n                # Next action from target + prior\n                next_q_values = self.target_network(next_states)\n                next_prior = self.prior_network(next_states)\n                next_q_plus_prior = next_q_values + next_prior\n                next_actions = next_q_plus_prior.argmax(dim=1, keepdim=True)\n\n                # Targets across all heads for uncertainty estimation\n                targets_all = []\n                for l in range(self.k):\n                    tq = self.target_network(next_states)\n                    tp = self.prior_network(next_states)\n                    target = tq[0, self.current_head] + tp[0, self.current_head]\n                    targets_all.append(target)\n                targets_all = torch.stack(targets_all, dim=0)  # [k, B, 1]\n\n                # Variance-based uncertainty\n                sigma2 = targets_all.var(dim=0, unbiased=False).squeeze(-1)  # [B]\n                sigmas.append(sigma2)\n\n                # Compute optimal ξ for EBS\n                xi = self._solve_for_xi(sigma2, self.min_ebs)\n                self.xi = xi\n\n                weights = 1 / (self.gamma**2 * sigma2 + xi)\n                targets = rewards + self.gamma * next_q_plus_prior.gather(1, next_actions) * (1 - dones)\n                td_error = q_plus_prior - targets\n\n                w = weights.unsqueeze(1)\n                loss = (w * td_error**2).sum() / w.sum()\n                losses.append(loss)\n\n        return sum(losses)\n\n    def _solve_for_xi(self, sigma2, min_ebs, tol=1e-4, max_iter=50):\n        lower, upper = 1e-6, 10.0\n        for _ in range(max_iter):\n            xi = (lower + upper) / 2\n            weights = 1 / (self.gamma**2 * sigma2 + xi)\n            num = weights.sum() ** 2\n            denom = (weights ** 2).sum()\n            ebs = num / denom\n            if abs(ebs - min_ebs) < tol:\n                return xi\n            if ebs < min_ebs:\n                lower = xi\n            else:\n                upper = xi\n        return xi  # fallback\n\n    def _wandb_train_step_dict(self):\n        log_dict = super()._wandb_train_step_dict()\n        log_dict[\"xi\"] = self.xi\n        return log_dict\n\n    def _save_dict(self):\n        save_dict = super()._save_dict()\n        save_dict[\"min_ebs\"] = self.min_ebs\n        return save_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:02:58.497324Z","iopub.execute_input":"2025-06-11T08:02:58.497646Z","iopub.status.idle":"2025-06-11T08:02:58.510781Z","shell.execute_reply.started":"2025-06-11T08:02:58.497620Z","shell.execute_reply":"2025-06-11T08:02:58.509949Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# env = [\"FrozenLake\", \"CartPole\", \"MountainCar\", \"SeaQuest\", \"LunarLander\"][3]\nenv = \"MountainCar\"\nprint(f\"{env} is selected.\")\n\nbase_agent_config = {\n    **ENVS[env][\"env\"],\n    \"default_batch_size\": 128,\n    \"gamma\": 0.99,\n    \"learning_rate\": 3e-4,\n    \"replay_buffer_capacity\":100_000,\n    \"tau\": 5e-3,\n    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"gradient_norm_clip\": 10.0,\n    \"start_training_after\": 1000,\n    \"normalize_rewards\": False,\n    \"scale_rewards\": None\n}\n\nbase_run_config = {\n    **ENVS[env][\"run\"],\n    \"learn_every\": 1,  # Apply learning every n steps of rollout\n    \"eval_every\": 10_000,  # Evaluate model approximately every n steps\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:03:32.208452Z","iopub.execute_input":"2025-06-11T08:03:32.208813Z","iopub.status.idle":"2025-06-11T08:03:32.215247Z","shell.execute_reply.started":"2025-06-11T08:03:32.208790Z","shell.execute_reply":"2025-06-11T08:03:32.214193Z"}},"outputs":[{"name":"stdout","text":"MountainCar is selected.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"eps_greedy_config = {\n    **base_agent_config,\n    \"eps_decay\": 0.9999,\n    \"eps_min\": 0.01,\n    \"epsilon\": 1.0,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:03:35.328524Z","iopub.execute_input":"2025-06-11T08:03:35.328953Z","iopub.status.idle":"2025-06-11T08:03:35.333959Z","shell.execute_reply.started":"2025-06-11T08:03:35.328924Z","shell.execute_reply":"2025-06-11T08:03:35.333044Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"bootstrap_dqn_config = {\n    **eps_greedy_config,\n    \"k\": 5,\n    \"bernoulli_p\": 1,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:03:37.007726Z","iopub.execute_input":"2025-06-11T08:03:37.008116Z","iopub.status.idle":"2025-06-11T08:03:37.012836Z","shell.execute_reply.started":"2025-06-11T08:03:37.008092Z","shell.execute_reply":"2025-06-11T08:03:37.011673Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"rpf_bootstrap_dqn_config = {\n    **bootstrap_dqn_config,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:03:38.527152Z","iopub.execute_input":"2025-06-11T08:03:38.527523Z","iopub.status.idle":"2025-06-11T08:03:38.532028Z","shell.execute_reply.started":"2025-06-11T08:03:38.527497Z","shell.execute_reply":"2025-06-11T08:03:38.530999Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"ue_bootstrap_dqn_config = {\n    **rpf_bootstrap_dqn_config,\n    \"xi\": 0.1,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:03:40.295416Z","iopub.execute_input":"2025-06-11T08:03:40.295706Z","iopub.status.idle":"2025-06-11T08:03:40.300301Z","shell.execute_reply.started":"2025-06-11T08:03:40.295686Z","shell.execute_reply":"2025-06-11T08:03:40.299320Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"### Epsilon Greedy DQN","metadata":{}},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\ntry:\n    eps_greedy_dqn_agent.train(**base_run_config)\n    wandb_run.finish()\nexcept KeyboardInterrupt:\n    pass","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"eps_greedy\",\n    \"config\": {**eps_greedy_config, **base_run_config, \"machine\": get_machine()},\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"eps_greedy\"],\n}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\neps_greedy_dqn_agent = EpsGreedyDQNAgent(wandb_run=wandb_run, **eps_greedy_config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Bootstrap DQN","metadata":{}},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"bootstrap\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bootstrap_dqn_agent = BootstrapDQNAgent(wandb_run=wandb_run, **bootstrap_dqn_config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\ntry:\n    bootstrap_dqn_agent.train(**base_run_config)\n    wandb_run.finish()\nexcept KeyboardInterrupt:\n    pass","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Bootstrap DQN with Randomized Prior Function","metadata":{}},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"randomized_prior\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"rpf_bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**rpf_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\nrpf_bootstrap_dqn_agent = RPFBootstrapDQNAgent(wandb_run=wandb_run, **rpf_bootstrap_dqn_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T19:23:12.458509Z","iopub.execute_input":"2025-06-10T19:23:12.459858Z","iopub.status.idle":"2025-06-10T19:23:35.148248Z","shell.execute_reply.started":"2025-06-10T19:23:12.459776Z","shell.execute_reply":"2025-06-10T19:23:35.146660Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masemanehnafe\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250610_192319-xibeaf9b</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/xibeaf9b' target=\"_blank\">randomized_prior</a></strong> to <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/xibeaf9b' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/xibeaf9b</a>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(wandb_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T19:23:40.303680Z","iopub.execute_input":"2025-06-10T19:23:40.304944Z","iopub.status.idle":"2025-06-10T19:23:45.792990Z","shell.execute_reply.started":"2025-06-10T19:23:40.304899Z","shell.execute_reply":"2025-06-10T19:23:45.791672Z"}},"outputs":[{"name":"stdout","text":"{'project': 'Asemaneh-Nafe-DQN-EXPLORE-HW', 'name': 'randomized_prior', 'save_code': True, 'tags': ['dqn', 'rpf_bootstrap'], 'config': {'env_name': 'MountainCar-v0', 'env_config': {}, 'seed': 43, 'default_batch_size': 128, 'gamma': 0.99, 'learning_rate': 0.0003, 'replay_buffer_capacity': 100000, 'tau': 0.005, 'device': 'cpu', 'gradient_norm_clip': 10.0, 'start_training_after': 1000, 'normalize_rewards': False, 'scale_rewards': None, 'eps_decay': 0.9999, 'eps_min': 0.01, 'epsilon': 1.0, 'k': 5, 'bernoulli_p': 1, 'max_episodes': 100000, 'max_steps': 300000, 'max_steps_per_episode': 100000, 'max_time': 9000.0, 'learn_every': 1, 'eval_every': 10000, 'machine': 'Kaggle'}}\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\ntry:\n    rpf_bootstrap_dqn_agent.train(**base_run_config)\n    wandb_run.finish()\nexcept KeyboardInterrupt:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T19:23:47.095922Z","iopub.execute_input":"2025-06-10T19:23:47.096330Z","iopub.status.idle":"2025-06-10T20:52:56.483324Z","shell.execute_reply.started":"2025-06-10T19:23:47.096301Z","shell.execute_reply":"2025-06-10T20:52:56.481966Z"}},"outputs":[{"name":"stdout","text":"episode: 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 50\n","output_type":"stream"},{"name":"stderr","text":"error: XDG_RUNTIME_DIR not set in the environment.\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 250\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 300\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 350\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 400\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 450\nepisode: 500\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 550\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 600\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 650\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 700\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 750\nepisode: 800\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 850\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 900\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 950\nepisode: 1000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1050\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1100\nepisode: 1150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1250\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1300\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1350\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1400\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1450\nepisode: 1500\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1600\nepisode: 1650\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1700\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1750\nepisode: 1800\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"Trained for 300000 steps.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>██▇██▆█▇▆▆▆▇▆█▆██▁█████▂▅▁▅▁██</td></tr><tr><td>eval_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_episode/sum_reward</td><td>▁▁▂▁▁▃▁▂▃▃▃▂▃▁▃▁▁█▁▁▁▁▁▇▄█▄█▁▁</td></tr><tr><td>train_episode/current_head</td><td>▃█▅▅▅▅▅▅▆▆▅█▅▁▆▆▅█▃▆▆▅▃▆▃▆▅█▅▅▆▅▅█▆▃▆▅▁▅</td></tr><tr><td>train_episode/episode_length</td><td>██████▆██▆██▆▇▇▆▇▇█▆▇▁▁█▇██▃▁▂████▂▆▁▅▅█</td></tr><tr><td>train_episode/mean_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▂▃▃▄▅▆▇▇█</td></tr><tr><td>train_episode/mean_return</td><td>▁▁▁▂▂▄▄▅▅▄▄▄▄▄▄▄▄▄▄▅▇▇▇▇▇▇▆▆▇▇▇▇▇███████</td></tr><tr><td>train_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_episode/sum_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▅▆▄█▆▅</td></tr><tr><td>train_episode/sum_reward</td><td>▁▁▁▁▁▁▁▆▁▁▁▂▁▁▁▃▃▃▂▂▂▅▆█▂▂▃▄▁▁█▁▆▁██▃▄▂▁</td></tr><tr><td>train_episode/var_return</td><td>▁▁▁▄▅▄▄▃▃▃▃▂▂▃▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>train_step/epsilon</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step/grad_norm</td><td>▁▁▁▂▁▂▁▂▁▃▇▆█▇██████████████████████████</td></tr><tr><td>train_step/loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▂▅▂▅█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>200</td></tr><tr><td>eval_episode/mean_reward</td><td>-1</td></tr><tr><td>eval_episode/sum_reward</td><td>-200</td></tr><tr><td>train_episode/current_head</td><td>4</td></tr><tr><td>train_episode/episode_length</td><td>34</td></tr><tr><td>train_episode/mean_loss</td><td>4445.82356</td></tr><tr><td>train_episode/mean_return</td><td>-78.71363</td></tr><tr><td>train_episode/mean_reward</td><td>-1</td></tr><tr><td>train_episode/sum_loss</td><td>151158.0011</td></tr><tr><td>train_episode/sum_reward</td><td>-34</td></tr><tr><td>train_episode/var_return</td><td>93.07143</td></tr><tr><td>train_step/epsilon</td><td>1</td></tr><tr><td>train_step/grad_norm</td><td>10.0</td></tr><tr><td>train_step/loss</td><td>7155.25781</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">randomized_prior</strong> at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/xibeaf9b' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/xibeaf9b</a><br> View project at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a><br>Synced 5 W&B file(s), 30 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250610_192319-xibeaf9b/logs</code>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"### Uncertainty Estimation for Sample Efficient RPF Bootstrap DQN","metadata":{}},{"cell_type":"markdown","source":"# bounes 1","metadata":{}},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"uncertainty_estimation\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"ue_bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**ue_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\nprint(wandb_config)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:04:05.568470Z","iopub.execute_input":"2025-06-11T08:04:05.568790Z","iopub.status.idle":"2025-06-11T08:04:24.786809Z","shell.execute_reply.started":"2025-06-11T08:04:05.568766Z","shell.execute_reply":"2025-06-11T08:04:24.785740Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masemanehnafe\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250611_080412-xha6v6mg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/xha6v6mg' target=\"_blank\">uncertainty_estimation</a></strong> to <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/xha6v6mg' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/xha6v6mg</a>"},"metadata":{}},{"name":"stdout","text":"{'project': 'Asemaneh-Nafe-DQN-EXPLORE-HW', 'name': 'uncertainty_estimation', 'save_code': True, 'tags': ['dqn', 'ue_bootstrap'], 'config': {'env_name': 'MountainCar-v0', 'env_config': {}, 'seed': 43, 'default_batch_size': 128, 'gamma': 0.99, 'learning_rate': 0.0003, 'replay_buffer_capacity': 100000, 'tau': 0.005, 'device': 'cpu', 'gradient_norm_clip': 10.0, 'start_training_after': 1000, 'normalize_rewards': False, 'scale_rewards': None, 'eps_decay': 0.9999, 'eps_min': 0.01, 'epsilon': 1.0, 'k': 5, 'bernoulli_p': 1, 'xi': 0.1, 'max_episodes': 100000, 'max_steps': 300000, 'max_steps_per_episode': 100000, 'max_time': 9000.0, 'learn_every': 1, 'eval_every': 10000, 'machine': 'Kaggle'}}\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"class UEBootstrapDQNAgent(RPFBootstrapDQNAgent):\n    def __init__(self, min_ebs: float = 32, xi = None, **kwargs):\n        super().__init__(**kwargs)\n        self.min_ebs = min_ebs  # Target effective batch size\n        self.xi = None\n\n    def _compute_loss(self, batch):\n        states = batch[\"state\"]            # [B, S]\n        actions = batch[\"action\"].unsqueeze(1)  # [B,1]\n        rewards = batch[\"reward\"].unsqueeze(1)  # [B,1]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"].unsqueeze(1)      # [B,1]\n        masks = batch[\"mask\"]             # [B, K]\n\n        B = states.size(0)\n\n        all_q = self.q_network(states) + self.prior_network(states)          # [B, K, A]\n        all_q_tgt = self.target_network(next_states) + self.prior_network(next_states)  # [B, K, A]\n\n        total_loss = 0.0\n        log_ebs = []\n\n        for j in range(self.k):\n            mask_j = masks[:, j]           # [B]\n            if mask_j.sum() == 0:\n                continue\n\n            idx = mask_j.nonzero(as_tuple=True)[0]\n            s_j = states[idx]\n            a_j = actions[idx]\n            r_j = rewards[idx]\n            ns_j = next_states[idx]\n            d_j = dones[idx]\n\n            q_j = (all_q[idx, j]          # [n_j, A]\n                   .gather(1, a_j))        # [n_j,1]\n\n            with torch.no_grad():\n                tgt_j = all_q_tgt[idx, j]\n                a_prime = tgt_j.argmax(dim=1, keepdim=True)  # [n_j,1]\n                T_j = r_j + self.gamma * tgt_j.gather(1, a_prime) * (1 - d_j)  # [n_j,1]\n\n                # Compute uncertainty across heads\n                x_l = []\n                for l in range(self.k):\n                    tmp = all_q_tgt[idx, l].gather(1, a_prime)\n                    x_l.append(tmp)\n                X = torch.stack([tmp.squeeze(1) for tmp in x_l], dim=1)  # [n_j, k]\n                sigma2 = X.var(dim=1, unbiased=False, keepdim=True)      # [n_j, 1]\n\n\n            # Solve for xi such that EBS ≥ min_ebs\n            xi = self._solve_for_xi(sigma2.squeeze(), self.min_ebs)\n            self.xi = xi\n\n            weights = 1.0 / (self.gamma ** 2 * sigma2 + xi)  # [n_j,1]\n\n            loss_j = (weights * (q_j - T_j) ** 2).sum() / weights.sum()\n            total_loss += loss_j\n            log_ebs.append(((weights.sum() ** 2) / (weights ** 2).sum()).item())\n\n        loss = total_loss / self.k\n        self._last_ebs = torch.tensor(log_ebs).mean().item()\n        return loss\n\n    def _solve_for_xi(self, sigma2, min_ebs, tol=1e-3, max_iter=50):\n        lo, hi = 1e-8, 1e3\n        for _ in range(max_iter):\n            xi = (lo + hi) / 2\n            w = 1.0 / (self.gamma ** 2 * sigma2 + xi)\n            ebs = (w.sum() ** 2) / (w ** 2).sum()\n            if abs(ebs - min_ebs) < tol:\n                return xi\n            if ebs < min_ebs:\n                lo = xi\n            else:\n                hi = xi\n        return xi\n\n    def _wandb_train_step_dict(self):\n        log = super()._wandb_train_step_dict()\n        log[\"train_step/xi\"] = self.xi\n        log[\"train_step/EBS\"] = self._last_ebs\n        return log\n\n    def _save_dict(self):\n        save = super()._save_dict()\n        save[\"min_ebs\"] = self.min_ebs\n        return save\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:58:32.448342Z","iopub.execute_input":"2025-06-11T08:58:32.448656Z","iopub.status.idle":"2025-06-11T08:58:38.174628Z","shell.execute_reply.started":"2025-06-11T08:58:32.448631Z","shell.execute_reply":"2025-06-11T08:58:38.173749Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"ue_bootstrap_dqn_agent = UEBootstrapDQNAgent(wandb_run=wandb_run, **ue_bootstrap_dqn_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:58:48.326376Z","iopub.execute_input":"2025-06-11T08:58:48.327104Z","iopub.status.idle":"2025-06-11T08:58:54.045972Z","shell.execute_reply.started":"2025-06-11T08:58:48.327076Z","shell.execute_reply":"2025-06-11T08:58:54.045099Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nue_bootstrap_dqn_agent.train(**base_run_config)\nwandb_run.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:58:54.047166Z","iopub.execute_input":"2025-06-11T08:58:54.047416Z","iopub.status.idle":"2025-06-11T11:29:04.232247Z","shell.execute_reply.started":"2025-06-11T08:58:54.047390Z","shell.execute_reply":"2025-06-11T11:29:04.230336Z"}},"outputs":[{"name":"stdout","text":"episode: 0\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nerror: XDG_RUNTIME_DIR not set in the environment.\n","output_type":"stream"},{"name":"stdout","text":"episode: 50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 250\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 300\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 350\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 400\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 450\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 500\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 550\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 600\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 650\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 700\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 750\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 800\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 850\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 900\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 950\nepisode: 1000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1050\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1100\nepisode: 1150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1250\nTrained for 229084 steps.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>█████████████████▁▆█▆▅█</td></tr><tr><td>eval_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_episode/sum_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▃▁▃▄▁</td></tr><tr><td>train_episode/current_head</td><td>▁▁▅▁▆▆▆▆▅█▅▁▆▆▆▅██▃▃▁▅▃▃▆▆▁▃▆▁█▅▃▅▆▁▁▁▃█</td></tr><tr><td>train_episode/episode_length</td><td>████████████████████▂▂▃▂▂█▂▁▆▆▄▄█▂▂▅▇▂▇▆</td></tr><tr><td>train_episode/mean_loss</td><td>▁▂▃▃▄▅▅▆▆▆▄▄▅▆▆▆▅▇█▄▅▄▄▅▃▃▃▃▃▃▂▃▄▂▂▂▂▂▃▂</td></tr><tr><td>train_episode/mean_return</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▆▇▇▇█████</td></tr><tr><td>train_episode/mean_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_episode/sum_loss</td><td>▁▁▁▃▃▄▅▄▄▃▄▆▄▄▅▄▄▅▄▄██▆▇▄▃▄▃▂▃▂▂▂▂▂▁▂▁▂▁</td></tr><tr><td>train_episode/sum_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▄▄▂▁▄▂▂▃▂▂█</td></tr><tr><td>train_episode/var_return</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▇▇▇█████</td></tr><tr><td>train_step/EBS</td><td>███████▇▄▂█▁▇▇▇█▇▇▆▆▅▅▁▁▃▇▇▇▇▆▅▆▇▇▆▇▇▇▇▆</td></tr><tr><td>train_step/epsilon</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step/grad_norm</td><td>▁▃███▄▅█████████▄████▆█▆█▂█▃████████████</td></tr><tr><td>train_step/loss</td><td>▁▃▂▆▁▁▁▁▁▆▂▁▁▁▄▁▅▁▁▁▁▁▁▁▃▁▂▁█▁▁▁▂▁▁▁▁▅▁▁</td></tr><tr><td>train_step/xi</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_episode/episode_length</td><td>194</td></tr><tr><td>eval_episode/mean_reward</td><td>-1</td></tr><tr><td>eval_episode/sum_reward</td><td>-194</td></tr><tr><td>train_episode/current_head</td><td>1</td></tr><tr><td>train_episode/episode_length</td><td>5</td></tr><tr><td>train_episode/mean_loss</td><td>1.17666</td></tr><tr><td>train_episode/mean_return</td><td>-82.93343</td></tr><tr><td>train_episode/mean_reward</td><td>-1</td></tr><tr><td>train_episode/sum_loss</td><td>5.88329</td></tr><tr><td>train_episode/sum_reward</td><td>-5</td></tr><tr><td>train_episode/var_return</td><td>48.87109</td></tr><tr><td>train_step/EBS</td><td>59.16792</td></tr><tr><td>train_step/epsilon</td><td>1</td></tr><tr><td>train_step/grad_norm</td><td>10.0</td></tr><tr><td>train_step/loss</td><td>4.69344</td></tr><tr><td>train_step/xi</td><td>0.0</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">uncertainty_estimation</strong> at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/xha6v6mg' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/xha6v6mg</a><br> View project at: <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a><br>Synced 5 W&B file(s), 23 media file(s), 15 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250611_080412-xha6v6mg/logs</code>"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"# bounes 2 IV-DQN","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport random\nfrom copy import deepcopy\n\n\nclass VarQNetwork(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.shared = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, 64),\n            nn.ReLU()\n        )\n        self.mu_head = nn.Linear(64, output_dim)\n        self.var_head = nn.Linear(64, output_dim)\n\n    def forward(self, x):\n        h = self.shared(x)\n        mu = self.mu_head(h)\n        var = F.softplus(self.var_head(h)) + 1e-4  # ensure positivity\n        return mu, var\n\n\ndef ivrl_loss(mu_pred, target, sigma2_pred, xi):\n    inv_sigma2 = 1.0 / (sigma2_pred + 1e-6)\n    diff = target - mu_pred\n    return torch.mean(0.5 * torch.log(sigma2_pred + 1e-6) + 0.5 * xi * diff.pow(2) * inv_sigma2)\n\n\ndef compute_mixture_variance(mus, vars_):\n    mean_all = mus.mean(dim=0)\n    return vars_.mean(dim=0) + (mus ** 2).mean(dim=0) - mean_all ** 2\n\n\ndef estimate_xi(sigma2, mebs):\n    # Use a simple iterative method to estimate xi to meet EBS >= MEBS\n    xi = 1.0\n    for _ in range(10):\n        weights = 1.0 / (sigma2 + 1e-6)\n        ebs = (weights.sum() ** 2) / (weights ** 2).sum()\n        if ebs >= mebs:\n            break\n        xi *= 1.5\n    return xi\n\n\nclass UEBootstrapDQNAgent:\n    def __init__(self, state_dim, action_dim, N=5, gamma=0.99, tau=0.01, lr=1e-3, device='cuda'):\n        self.N = N\n        self.gamma = gamma\n        self.tau = tau\n        self.device = device\n        self.q_nets = [VarQNetwork(state_dim, action_dim).to(device) for _ in range(N)]\n        self.target_nets = [deepcopy(net).to(device) for net in self.q_nets]\n        self.prior_nets = [VarQNetwork(state_dim, action_dim).to(device).eval() for _ in range(N)]\n        for p in self.prior_nets:\n            for param in p.parameters():\n                param.requires_grad = False\n        self.optimizers = [torch.optim.Adam(net.parameters(), lr=lr) for net in self.q_nets]\n        self.replay_buffer = []\n\n    def select_action(self, state):\n        state = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n        i = random.randint(0, self.N - 1)\n        with torch.no_grad():\n            mu, _ = self.q_nets[i](state)\n            prior, _ = self.prior_nets[i](state)\n            q = mu + prior\n        return torch.argmax(q, dim=1).item()\n\n    def store(self, transition):\n        self.replay_buffer.append(transition)\n\n    def train_step(self, batch_size=32, delta_rpf=0.0, p_mask=0.5, mebs=8):\n        if len(self.replay_buffer) < batch_size:\n            return\n\n        minibatch = random.sample(self.replay_buffer, batch_size)\n        states, actions, next_states, rewards, dones = zip(*minibatch)\n        states = torch.tensor(states, dtype=torch.float32).to(self.device)\n        actions = torch.tensor(actions, dtype=torch.long).unsqueeze(1).to(self.device)\n        next_states = torch.tensor(next_states, dtype=torch.float32).to(self.device)\n        rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1).to(self.device)\n        dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1).to(self.device)\n\n        for j in range(self.N):\n            mask = (torch.rand(batch_size) < p_mask).float().to(self.device).unsqueeze(1)\n\n            mu_q, var_q = self.q_nets[j](states)\n            mu_q = mu_q.gather(1, actions)\n            var_q = var_q.gather(1, actions)\n\n            with torch.no_grad():\n                mu_next, _ = self.target_nets[j](next_states)\n                prior_next, _ = self.prior_nets[j](next_states)\n                next_q = mu_next + delta_rpf * prior_next\n                next_actions = torch.argmax(next_q, dim=1, keepdim=True)\n\n                mu_tgt = []\n                var_tgt = []\n                for l in range(self.N):\n                    mu_l, var_l = self.target_nets[l](next_states)\n                    prior_l, _ = self.prior_nets[l](next_states)\n                    mu = mu_l.gather(1, next_actions) + delta_rpf * prior_l.gather(1, next_actions)\n                    var = var_l.gather(1, next_actions)\n                    mu_tgt.append(mu)\n                    var_tgt.append(var)\n\n                mu_tgt = torch.stack(mu_tgt)\n                var_tgt = torch.stack(var_tgt)\n                mix_var = compute_mixture_variance(mu_tgt, var_tgt)\n                mean_target = mu_tgt[j]\n                target = rewards + self.gamma * (1 - dones) * mean_target\n\n            xi = estimate_xi(mix_var, mebs)\n\n            loss = ivrl_loss(mu_q, target, var_q, xi)\n            self.optimizers[j].zero_grad()\n            loss.backward()\n            self.optimizers[j].step()\n\n            # Soft update\n            for param, tgt_param in zip(self.q_nets[j].parameters(), self.target_nets[j].parameters()):\n                tgt_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * tgt_param.data)\n\n    def save(self, path):\n        torch.save([net.state_dict() for net in self.q_nets], path)\n\n    def load(self, path):\n        states = torch.load(path)\n        for net, state in zip(self.q_nets, states):\n            net.load_state_dict(state)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:52:00.158126Z","iopub.execute_input":"2025-06-11T11:52:00.158581Z","iopub.status.idle":"2025-06-11T11:52:00.194144Z","shell.execute_reply.started":"2025-06-11T11:52:00.158548Z","shell.execute_reply":"2025-06-11T11:52:00.193088Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"class UEBootstrapDQNAgent(RPFBootstrapDQNAgent):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        state_dim = self.env.observation_space.shape[0]\n        action_dim = self.env.action_space.n\n        device = kwargs.get(\"device\", \"cuda\")\n\n        self.q_nets = [VarQNetwork(state_dim, action_dim).to(device) for _ in range(self.k)]\n        self.target_nets = [deepcopy(net).to(device) for net in self.q_nets]\n\n        self.prior_nets = [VarQNetwork(state_dim, action_dim).to(device).eval() for _ in range(self.k)]\n        for p in self.prior_nets:\n            for param in p.parameters():\n                param.requires_grad = False\n        self.optimizers = [torch.optim.Adam(net.parameters(), lr=kwargs['learning_rate']) for net in self.q_nets]\n\n    def train_step(self, batch_size=32, delta_rpf=0.0, p_mask=0.5, mebs=8):\n        if len(self.replay_buffer) < batch_size:\n            return\n\n        minibatch = random.sample(self.replay_buffer, batch_size)\n        states, actions, next_states, rewards, dones = zip(*minibatch)\n        states = torch.tensor(states, dtype=torch.float32).to(self.device)\n        actions = torch.tensor(actions, dtype=torch.long).unsqueeze(1).to(self.device)\n        next_states = torch.tensor(next_states, dtype=torch.float32).to(self.device)\n        rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1).to(self.device)\n        dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1).to(self.device)\n\n        for j in range(self.N):\n            mask = (torch.rand(batch_size) < p_mask).float().to(self.device).unsqueeze(1)\n\n            mu_q, var_q = self.q_nets[j](states)\n            mu_q = mu_q.gather(1, actions)\n            var_q = var_q.gather(1, actions)\n\n            with torch.no_grad():\n                mu_next, _ = self.target_nets[j](next_states)\n                prior_next, _ = self.prior_nets[j](next_states)\n                next_q = mu_next + delta_rpf * prior_next\n                next_actions = torch.argmax(next_q, dim=1, keepdim=True)\n\n                mu_tgt = []\n                var_tgt = []\n                for l in range(self.N):\n                    mu_l, var_l = self.target_nets[l](next_states)\n                    prior_l, _ = self.prior_nets[l](next_states)\n                    mu = mu_l.gather(1, next_actions) + delta_rpf * prior_l.gather(1, next_actions)\n                    var = var_l.gather(1, next_actions)\n                    mu_tgt.append(mu)\n                    var_tgt.append(var)\n\n                mu_tgt = torch.stack(mu_tgt)\n                var_tgt = torch.stack(var_tgt)\n                mix_var = compute_mixture_variance(mu_tgt, var_tgt)\n                mean_target = mu_tgt[j]\n                target = rewards + self.gamma * (1 - dones) * mean_target\n\n            xi = estimate_xi(mix_var, mebs)\n\n            loss = ivrl_loss(mu_q, target, var_q, xi)\n            self.optimizers[j].zero_grad()\n            loss.backward()\n            self.optimizers[j].step()\n\n            for param, tgt_param in zip(self.q_nets[j].parameters(), self.target_nets[j].parameters()):\n                tgt_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * tgt_param.data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T12:14:58.417911Z","iopub.execute_input":"2025-06-11T12:14:58.418240Z","iopub.status.idle":"2025-06-11T12:15:04.314094Z","shell.execute_reply.started":"2025-06-11T12:14:58.418218Z","shell.execute_reply":"2025-06-11T12:15:04.313115Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"uncertainty_estimation\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"ue_bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**ue_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\nprint(wandb_config)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T12:03:57.381958Z","iopub.execute_input":"2025-06-11T12:03:57.382726Z","iopub.status.idle":"2025-06-11T12:04:10.747626Z","shell.execute_reply.started":"2025-06-11T12:03:57.382688Z","shell.execute_reply":"2025-06-11T12:04:10.746651Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250611_120357-njz0lutv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/njz0lutv' target=\"_blank\">uncertainty_estimation</a></strong> to <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/njz0lutv' target=\"_blank\">https://wandb.ai/asemanehnafe/Asemaneh-Nafe-DQN-EXPLORE-HW/runs/njz0lutv</a>"},"metadata":{}},{"name":"stdout","text":"{'project': 'Asemaneh-Nafe-DQN-EXPLORE-HW', 'name': 'uncertainty_estimation', 'save_code': True, 'tags': ['dqn', 'ue_bootstrap'], 'config': {'env_name': 'MountainCar-v0', 'env_config': {}, 'seed': 43, 'default_batch_size': 128, 'gamma': 0.99, 'learning_rate': 0.0003, 'replay_buffer_capacity': 100000, 'tau': 0.005, 'device': 'cpu', 'gradient_norm_clip': 10.0, 'start_training_after': 1000, 'normalize_rewards': False, 'scale_rewards': None, 'eps_decay': 0.9999, 'eps_min': 0.01, 'epsilon': 1.0, 'k': 5, 'bernoulli_p': 1, 'xi': 0.1, 'max_episodes': 100000, 'max_steps': 300000, 'max_steps_per_episode': 100000, 'max_time': 9000.0, 'learn_every': 1, 'eval_every': 10000, 'machine': 'Google Colab'}}\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"ue_bootstrap_dqn_agent = UEBootstrapDQNAgent(wandb_run=wandb_run, **rpf_bootstrap_dqn_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T12:15:06.294248Z","iopub.execute_input":"2025-06-11T12:15:06.294573Z","iopub.status.idle":"2025-06-11T12:15:12.112337Z","shell.execute_reply.started":"2025-06-11T12:15:06.294549Z","shell.execute_reply":"2025-06-11T12:15:12.111327Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nue_bootstrap_dqn_agent.train(**base_run_config)\nwandb_run.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T12:15:14.473229Z","iopub.execute_input":"2025-06-11T12:15:14.473565Z"}},"outputs":[{"name":"stdout","text":"episode: 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 250\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 300\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 350\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 400\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 450\nepisode: 500\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 550\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 600\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 650\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 700\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 750\nepisode: 800\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 850\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 900\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 950\nepisode: 1000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1050\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1100\nepisode: 1150\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1250\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1300\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1350\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1400\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n","output_type":"stream"},{"name":"stdout","text":"episode: 1450\nepisode: 1500\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"I accidentally closed the Kaggle tab, but the run continued and the results are available on Weights & Biases.","metadata":{}}]}